{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import importlib\n",
    "from timeit import timeit\n",
    "import logging\n",
    "import sys\n",
    "import importlib\n",
    "import time\n",
    "import multiprocessing as mp\n",
    "import multiprocessing.pool\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import h5py\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import numba\n",
    "import sklearn.linear_model\n",
    "\n",
    "import ms_utils\n",
    "import browser\n",
    "import interface\n",
    "import ms_database\n",
    "import ms_run_files\n",
    "\n",
    "import sandbox\n",
    "\n",
    "import line_profiler\n",
    "profile = line_profiler.LineProfiler()\n",
    "# heat.evolve = profile(heat.evolve)\n",
    "# profile.print_stats()\n",
    "\n",
    "def reload():\n",
    "    importlib.reload(ms_run_files)\n",
    "    importlib.reload(ms_utils)\n",
    "    importlib.reload(browser)\n",
    "    importlib.reload(interface)\n",
    "    importlib.reload(sandbox)\n",
    "    importlib.reload(ms_database)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_candidate_peptide_indices_for_nodes(\n",
    "    inet,\n",
    "    database,\n",
    "    parameters\n",
    "):\n",
    "    # TODO: Docstring\n",
    "    ms_utils.LOGGER.info(\n",
    "        f\"Writing node candidates to {inet.file_name}\"\n",
    "    )\n",
    "    max_ppm = parameters[\"annotation_ppm\"]\n",
    "    self_mzs = inet.get_ion_coordinates(\"FRAGMENT_MZ\")\n",
    "    mz_order = np.argsort(self_mzs)\n",
    "    database_mzs = database.get_fragment_coordinates(\"mz\")\n",
    "    mz_transform = np.log(self_mzs[mz_order]) * 10**6\n",
    "    low_limits = np.searchsorted(\n",
    "        np.log(database_mzs) * 10**6,\n",
    "        mz_transform - max_ppm,\n",
    "        \"left\"\n",
    "    )\n",
    "    high_limits = np.searchsorted(\n",
    "        np.log(database_mzs) * 10**6,\n",
    "        mz_transform + max_ppm,\n",
    "        \"right\"\n",
    "    )\n",
    "    inv_order = np.argsort(mz_order)\n",
    "    return low_limits[inv_order], high_limits[inv_order]\n",
    "\n",
    "\n",
    "@numba.njit(nogil=True, cache=True)\n",
    "def score_annotations(\n",
    "    candidates,\n",
    "    edge_contributions,\n",
    "    indptr,\n",
    "    indices,\n",
    "    peptide_pointers,\n",
    "    low_peptide_indices,\n",
    "    high_peptide_indices,\n",
    "    peptide_count,\n",
    "):\n",
    "    annotated_ions = np.empty(candidates.shape[0], np.int64)\n",
    "    annotated_peptides = np.empty(candidates.shape[0], np.int64)\n",
    "    annotated_scores = np.empty(candidates.shape[0], np.float64)\n",
    "    current_annotation_index = 0\n",
    "    for index in np.flatnonzero(candidates):\n",
    "        local_edge_contributions = edge_contributions[indptr[index]: indptr[index + 1]]\n",
    "        good_edges = np.flatnonzero(local_edge_contributions > 0)\n",
    "        if good_edges.shape[0] == 0:\n",
    "            continue\n",
    "        neighbors = indices[indptr[index]: indptr[index + 1]][good_edges]\n",
    "        local_edge_contributions = local_edge_contributions[good_edges]\n",
    "        l = low_peptide_indices[index]\n",
    "        h = high_peptide_indices[index]\n",
    "        candidate_peptides = peptide_pointers[l:h]\n",
    "        candidate_peptide_scores = np.zeros(peptide_count, np.int64)\n",
    "        for edge_contribution, neighbor_index in zip(local_edge_contributions, neighbors):\n",
    "            l = low_peptide_indices[neighbor_index]\n",
    "            h = high_peptide_indices[neighbor_index]\n",
    "            if l == h:\n",
    "                continue\n",
    "            neighbor_peptides = peptide_pointers[l:h]\n",
    "            candidate_peptide_scores[neighbor_peptides] += edge_contribution\n",
    "        candidate_peptide_scores = candidate_peptide_scores[candidate_peptides]\n",
    "        hits = np.flatnonzero(candidate_peptide_scores)\n",
    "        if hits.shape[0] == 0:\n",
    "            continue\n",
    "        candidate_peptides = candidate_peptides[hits]\n",
    "        candidate_peptide_scores = candidate_peptide_scores[hits]\n",
    "    #     count_frequency = np.bincount(candidate_peptide_counts)\n",
    "    #     if count_frequency[-1] != 1:\n",
    "    #         continue\n",
    "    #     print(index, candidate_peptides, candidate_peptide_counts)\n",
    "        max_index = np.argmax(candidate_peptide_scores)\n",
    "        peptide = candidate_peptides[max_index]\n",
    "        score = candidate_peptide_scores[max_index]\n",
    "        annotated_ions[current_annotation_index] = index\n",
    "        annotated_peptides[current_annotation_index] = peptide\n",
    "        annotated_scores[current_annotation_index] = score\n",
    "        current_annotation_index += 1\n",
    "    annotated_ions = annotated_ions[:current_annotation_index]\n",
    "    annotated_peptides = annotated_peptides[:current_annotation_index]\n",
    "    annotated_scores = annotated_scores[:current_annotation_index]\n",
    "    return annotated_ions, annotated_peptides, annotated_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inet = ms_run_files.HDF_Network_File(\n",
    "    \"/home/sander/Documents/Proteomics/data/ecoli_test/28Oct2016_068.inet.hdf\"\n",
    ")\n",
    "evi = ms_run_files.HDF_Evidence_File(inet)\n",
    "database = ms_database.HDF_Database_File(\n",
    "    \"/home/sander/Documents/Proteomics/data/databases/crap_ecoli_concatenated_decoy.hdf\"\n",
    ")\n",
    "parameters = ms_utils.read_parameters_from_json_file(default=\"annotation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_peptide_indices, high_peptide_indices = get_candidate_peptide_indices_for_nodes(\n",
    "    inet,\n",
    "    database,\n",
    "    parameters\n",
    ")\n",
    "peptide_pointers = database.get_fragment_coordinates(\"peptide_index\")\n",
    "indptr, indices, edge_pointers = inet.get_edges(symmetric=True, return_pointers=True)\n",
    "positive_counts = evi.get_edges()\n",
    "negative_counts = evi.get_edges(positive=False)\n",
    "peptide_sequences = database.read_dataset(\"sequence\", \"peptides\")\n",
    "decoys = database.read_dataset(\"decoy\", \"peptides\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# edge_contributions = positive_counts[edge_pointers] == 9\n",
    "edge_contributions = positive_counts[edge_pointers] - negative_counts[edge_pointers]\n",
    "# edge_contributions = positive_counts[edge_pointers] >= 4\n",
    "np.bincount(edge_contributions + 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates = (high_peptide_indices > low_peptide_indices)\n",
    "thread_count = 8\n",
    "with multiprocessing.pool.ThreadPool(thread_count) as p:\n",
    "    results = p.starmap(\n",
    "        score_annotations,\n",
    "        [\n",
    "            (\n",
    "                candidates[i::thread_count],\n",
    "                edge_contributions,\n",
    "                indptr,\n",
    "                indices,\n",
    "                peptide_pointers,\n",
    "                low_peptide_indices,\n",
    "                high_peptide_indices,\n",
    "                peptide_sequences.shape[0],\n",
    "            ) for i in range(thread_count)\n",
    "        ]\n",
    "    )\n",
    "annotated_ions = np.concatenate([r[0] for r in results])\n",
    "annotated_peptides = np.concatenate([r[1] for r in results])\n",
    "annotated_scores = np.concatenate([r[2] for r in results])\n",
    "annotated_decoys = decoys[annotated_peptides]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(int(np.max(annotated_scores))):\n",
    "    print(i, np.bincount(annotated_decoys[annotated_scores > i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_i = 519\n",
    "\n",
    "print(np.argmax(annotated_scores))\n",
    "\n",
    "annotated_ions[max_i], annotated_peptides[max_i], annotated_scores[max_i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 42853\n",
    "print(6659 in peptide_pointers[low_peptide_indices[i]: high_peptide_indices[i]])\n",
    "p = np.flatnonzero(peptide_pointers == 6659)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z = np.concatenate(\n",
    "#     [\n",
    "#         280718 in peptide_pointers[\n",
    "#             low_peptide_indices[n]: high_peptide_indices[n]\n",
    "#         ] for n in indices[indptr[i]: indptr[i+1]]\n",
    "#     ]\n",
    "# )\n",
    "# # np.bincount(z)[p]\n",
    "# z\n",
    "l = 0\n",
    "for n in indices[indptr[i]: indptr[i+1]]:\n",
    "    l += np.any(np.isin(p, np.arange(low_peptide_indices[n], high_peptide_indices[n])))\n",
    "#     l += 280718 in peptide_pointers[\n",
    "#         low_peptide_indices[n]: high_peptide_indices[n]\n",
    "#     ]\n",
    "    \n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.bincount(decoys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.njit(cache=True, nogil=True)\n",
    "def annotate_network(\n",
    "    queries,\n",
    "    indptr,\n",
    "    indices,\n",
    "    edge_pointers,\n",
    "    selected_edges,\n",
    "    low_limits,\n",
    "    high_limits,\n",
    "    peptide_pointers,\n",
    "):\n",
    "    peptide_count = np.max(peptide_pointers) + 1\n",
    "    count = len(queries)\n",
    "    score_results = np.empty(count, np.float64)\n",
    "    fragment_results = np.empty(count, np.int64)\n",
    "    index_results = np.empty(count, np.int64)\n",
    "    count_results = np.empty(count, np.int64)\n",
    "    current_i = 0\n",
    "    for ion_index in queries:\n",
    "        ion_start = indptr[ion_index]\n",
    "        ion_end = indptr[ion_index + 1]\n",
    "        good_neighbors = selected_edges[edge_pointers[ion_start: ion_end]]\n",
    "        if np.all(~good_neighbors):\n",
    "            continue\n",
    "        neighbors = indices[ion_start: ion_end][good_neighbors]\n",
    "        candidates = np.zeros(peptide_count, np.int64)\n",
    "        for neighbor_ion_index in neighbors:\n",
    "            peptide_low = low_limits[neighbor_ion_index]\n",
    "            peptide_high = high_limits[neighbor_ion_index]\n",
    "            if peptide_low == peptide_high:\n",
    "                continue\n",
    "            peptides = peptide_pointers[peptide_low: peptide_high]\n",
    "            candidates[peptides] += 1\n",
    "        peptide_low = low_limits[ion_index]\n",
    "        peptide_high = high_limits[ion_index]\n",
    "        if peptide_low == peptide_high:\n",
    "            continue\n",
    "        peptides = peptide_pointers[peptide_low: peptide_high]\n",
    "        local_candidates = candidates[peptides]\n",
    "        frequencies = np.bincount(local_candidates)\n",
    "        frequencies = np.cumsum(frequencies[:0:-1])[::-1]\n",
    "        for regression_index, value in enumerate(frequencies):\n",
    "            if value == 1:\n",
    "                break\n",
    "        else:\n",
    "            continue\n",
    "        if regression_index < 2:\n",
    "            continue\n",
    "        max_count = (len(frequencies) - 1)\n",
    "        regression_constant = np.log(frequencies[0])\n",
    "        regression_slope = (np.log(frequencies[regression_index]) - regression_constant) / regression_index\n",
    "        score = regression_constant + regression_slope * max_count\n",
    "        if score < 0:\n",
    "            score_results[current_i] = -score\n",
    "            hit_index = np.flatnonzero(local_candidates == max_count + 1)[0]\n",
    "            fragment = peptide_low + hit_index\n",
    "            fragment_results[current_i] = fragment\n",
    "            index_results[current_i] = ion_index\n",
    "            count_results[current_i] = max_count\n",
    "            current_i += 1\n",
    "    return (\n",
    "        score_results[:current_i],\n",
    "        fragment_results[:current_i],\n",
    "        index_results[:current_i],\n",
    "        count_results[:current_i]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: /home/sander/Documents/Proteomics/data/ecoli_test/28Oct2016_068.inet.hdf was created with version 2.0.200622 instead of 2.0.200625\n",
      "WARNING: /home/sander/Documents/Proteomics/data/ecoli_test/28Oct2016_068.evidence.hdf was created with version 2.0.200622 instead of 2.0.200625\n",
      "WARNING: /home/sander/Documents/Proteomics/data/ecoli_test/28Oct2016_068.inet.hdf was created with version 2.0.200622 instead of 2.0.200625\n",
      "WARNING: /home/sander/Documents/Proteomics/data/databases/crap_ecoli_concatenated_decoy.hdf was created with version 2.0.200623 instead of 2.0.200625\n"
     ]
    }
   ],
   "source": [
    "inet = ms_run_files.HDF_Network_File(\n",
    "    \"/home/sander/Documents/Proteomics/data/ecoli_test/28Oct2016_068.inet.hdf\"\n",
    ")\n",
    "evi = ms_run_files.HDF_Evidence_File(inet)\n",
    "database = ms_database.HDF_Database_File(\n",
    "    \"/home/sander/Documents/Proteomics/data/databases/crap_ecoli_concatenated_decoy.hdf\"\n",
    ")\n",
    "parameters = ms_utils.read_parameters_from_json_file(default=\"annotation\")\n",
    "parameters[\"edge_threshold\"] = \"2 * (positive_edges - negative_edges) > evidence_run_count\"\n",
    "parameters[\"edge_threshold\"] =  \"positive_edges > negative_edges\"\n",
    "import pyteomics\n",
    "import numexpr as ne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "threads = 8\n",
    "# LOGGER.info(f\"Reading {inet.file_name}\")\n",
    "inet_mzs = inet.get_ion_coordinates(\"FRAGMENT_MZ\")\n",
    "mz_order = np.argsort(inet_mzs)\n",
    "spectra_log_mzs = np.log(inet_mzs[mz_order]) * 10**6\n",
    "indptr, indices, edge_pointers = inet.get_edges(symmetric=True, return_pointers=True)\n",
    "positive_counts = evi.get_edges()\n",
    "negative_counts = evi.get_edges(positive=False)\n",
    "# LOGGER.info(f\"Reading database {database.file_name}\")\n",
    "peptide_pointers = database.get_fragment_coordinates(\"peptide_index\")\n",
    "database_log_mzs = np.log(database.get_fragment_coordinates(\"mz\")) * 10**6\n",
    "# LOGGER.info(\n",
    "#     f\"Matching fragments of {mgf_file_name} with {database.file_name}\"\n",
    "# )\n",
    "low_limits = np.searchsorted(\n",
    "    database_log_mzs,\n",
    "    spectra_log_mzs - parameters[\"annotation_ppm\"],\n",
    "    \"left\"\n",
    ")\n",
    "high_limits = np.searchsorted(\n",
    "    database_log_mzs,\n",
    "    spectra_log_mzs + parameters[\"annotation_ppm\"],\n",
    "    \"right\"\n",
    ")\n",
    "inv_order = np.argsort(mz_order)\n",
    "# LOGGER.info(\n",
    "#     f\"Annotating fragments of {mgf_file_name} with {database.file_name}\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_edges = ne.evaluate(\n",
    "    parameters[\"edge_threshold\"],\n",
    "    local_dict={\n",
    "        \"positive_edges\": evi.get_edges(),\n",
    "        \"negative_edges\": evi.get_edges(positive=False),\n",
    "        \"evidence_run_count\": evi.run_count\n",
    "    },\n",
    "    global_dict={},\n",
    ")\n",
    "with multiprocessing.pool.ThreadPool(threads) as p:\n",
    "    results = p.starmap(\n",
    "        annotate_network,\n",
    "        [\n",
    "            (\n",
    "                np.arange(i, inet.node_count, threads),\n",
    "                indptr,\n",
    "                indices,\n",
    "                edge_pointers,\n",
    "                selected_edges,\n",
    "                low_limits[inv_order],\n",
    "                high_limits[inv_order],\n",
    "                peptide_pointers,\n",
    "            ) for i in range(threads)\n",
    "        ]\n",
    "    )\n",
    "scores = np.concatenate([r[0] for r in results])\n",
    "fragments = np.concatenate([r[1] for r in results])\n",
    "ion_indices = np.concatenate([r[2] for r in results])\n",
    "count_results = np.concatenate([r[3] for r in results])\n",
    "del results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_annotated_csv(\n",
    "    scores,\n",
    "    fragments,\n",
    "    ion_indices,\n",
    "    count_results,\n",
    "    inet,\n",
    "    database,\n",
    "    peptide_pointers,\n",
    "    out_file_name,\n",
    "):\n",
    "#     LOGGER.info(f\"Exporting {out_file_name}\")\n",
    "    peptides = peptide_pointers[fragments]\n",
    "    decoys = database.read_dataset(\"decoy\", \"peptides\")\n",
    "    peptide_modifications = database.read_dataset(\"modifications\", \"peptides\")\n",
    "    peptide_sequences = database.read_dataset(\"sequence\", \"peptides\")\n",
    "    # selection = np.flatnonzero((scores < score_cutoff) & (~decoys[peptides]))\n",
    "    fragment_ion_numbers = database.get_fragment_coordinates(\"ionnumber\")\n",
    "    fragment_is_y_ion = database.get_fragment_coordinates(\"y_ion\")\n",
    "    self_coordinates = inet.get_ion_coordinates(inet.dimensions)\n",
    "    self_ints = inet.get_ion_coordinates(\"FRAGMENT_LOGINT\")\n",
    "    with open(out_file_name, \"w\") as raw_outfile:\n",
    "        outfile = csv.writer(raw_outfile)\n",
    "        header = [\"Fragment_index\"]\n",
    "        header += inet.dimensions\n",
    "        header += [\n",
    "            \"Fragment_ion_number\",\n",
    "            \"Fragment_is_y_ion\",\n",
    "            \"Peptide_sequence\",\n",
    "            \"peptide_mods\",\n",
    "            \"Score\",\n",
    "            \"Count\",\n",
    "            \"Decoy\"\n",
    "        ]\n",
    "        outfile.writerow(header)\n",
    "        for i, ion_index in enumerate(ion_indices):\n",
    "            fragment_index = fragments[i]\n",
    "            peptide_index = peptides[i]\n",
    "            row = [ion_index]\n",
    "            row += [self_coordinate[ion_index] for self_coordinate in self_coordinates]\n",
    "            row += [\n",
    "                fragment_ion_numbers[fragment_index],\n",
    "                fragment_is_y_ion[fragment_index],\n",
    "                peptide_sequences[peptide_index],\n",
    "                peptide_modifications[peptide_index],\n",
    "                scores[i],\n",
    "                count_results[i],\n",
    "                decoys[peptide_index],\n",
    "            ]\n",
    "            outfile.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "export_annotated_csv(\n",
    "    scores,\n",
    "    fragments,\n",
    "    ion_indices,\n",
    "    count_results,\n",
    "    inet,\n",
    "    database,\n",
    "    peptide_pointers,\n",
    "    out_file_name=\"/home/sander/Documents/Sandbox/aaa.csv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2592, 112, 0.041420118343195256)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoys = database.read_dataset(\"decoy\", \"peptides\")\n",
    "peptides = peptide_pointers[fragments]\n",
    "target_scores = scores[~decoys[peptides]]\n",
    "decoy_scores = scores[decoys[peptides]]\n",
    "scores, peptides, target_scores.shape, decoy_scores.shape\n",
    "score_cutoff = 3\n",
    "ts = np.sum(target_scores > score_cutoff)\n",
    "ds = np.sum(decoy_scores > score_cutoff)\n",
    "ts, ds, 1 - ts/(ts+ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([35921413,  1301386])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(selected_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.151 second"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spectra[0]['params']['rtinseconds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyteomics.mgf\n",
    "# mgf_file_name = \"/home/sander/Documents/Sandbox/test_msfragger/LFQ_TT5600_DDA_Micro_120_Min_Ecoli_01.mgf\"\n",
    "mgf_file_name = \"/home/sander/Documents/Sandbox/test_msfragger/LFQ_TT5600_GP_4sec_cycletime_Ecoli_500_600.mgf\"\n",
    "spectra = [spectrum for spectrum in pyteomics.mgf.read(mgf_file_name)]\n",
    "self_mzs = np.concatenate([spectrum[\"m/z array\"] for spectrum in spectra])\n",
    "self_ints = np.concatenate([spectrum[\"intensity array\"] for spectrum in spectra])\n",
    "spec_indptr = np.empty(len(spectra) + 1, np.int64)\n",
    "spec_indptr[0] = 0\n",
    "spec_indptr[1:] = np.cumsum([len(spectrum[\"m/z array\"]) for spectrum in spectra])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = ms_database.HDF_Database_File(parameters[\"database_file_name\"])\n",
    "db_mzs = db.get_fragment_coordinates(\"mz\")\n",
    "peptide_pointers = db.get_fragment_coordinates(\"peptide_index\")\n",
    "peptide_sequences = db.read_dataset(\"sequence\", \"peptides\")\n",
    "peptide_modifications = db.read_dataset(\"modifications\", \"peptides\")\n",
    "decoys = db.read_dataset(\"decoy\", \"peptides\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_ppm = parameters[\"annotation_ppm\"]\n",
    "mz_order = np.argsort(self_mzs)\n",
    "mz_transform = np.log(self_mzs[mz_order]) * 10**6\n",
    "low_limits = np.searchsorted(\n",
    "    np.log(db_mzs) * 10**6,\n",
    "    mz_transform - max_ppm,\n",
    "    \"left\"\n",
    ")\n",
    "high_limits = np.searchsorted(\n",
    "    np.log(db_mzs) * 10**6,\n",
    "    mz_transform + max_ppm,\n",
    "    \"right\"\n",
    ")\n",
    "inv_order = np.argsort(mz_order)\n",
    "low_limits = low_limits[inv_order]\n",
    "high_limits = high_limits[inv_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.njit(cache=True, nogil=True)\n",
    "def annotate_mgf(\n",
    "    queries,\n",
    "    spec_indptr,\n",
    "    low_limits,\n",
    "    high_limits,\n",
    "    peptide_pointers,\n",
    "):\n",
    "    peptide_count = np.max(peptide_pointers)\n",
    "    count = 0\n",
    "    for s in queries:\n",
    "        count += spec_indptr[s + 1] - spec_indptr[s]\n",
    "    score_results = np.zeros(count, np.float64)\n",
    "    fragment_results = np.zeros(count, np.int64)\n",
    "    index_results = np.zeros(count, np.int64)\n",
    "    count_results = np.zeros(count, np.int64)\n",
    "    current_i = 0\n",
    "    for spectrum_index in queries:\n",
    "        spectrum_start = spec_indptr[spectrum_index]\n",
    "        spectrum_end = spec_indptr[spectrum_index + 1]\n",
    "        candidates = np.zeros(peptide_count, np.int64)\n",
    "        for ion_index in range(spectrum_start, spectrum_end):\n",
    "            peptide_low = low_limits[ion_index]\n",
    "            peptide_high = high_limits[ion_index]\n",
    "            if peptide_low == peptide_high:\n",
    "                continue\n",
    "            peptides = peptide_pointers[peptide_low: peptide_high]\n",
    "            candidates[peptides] += 1\n",
    "        for ion_index in range(spectrum_start, spectrum_end):\n",
    "            peptide_low = low_limits[ion_index]\n",
    "            peptide_high = high_limits[ion_index]\n",
    "            if peptide_low == peptide_high:\n",
    "                continue\n",
    "            peptides = peptide_pointers[peptide_low: peptide_high]\n",
    "            local_candidates = candidates[peptides]\n",
    "            frequencies = np.bincount(local_candidates)\n",
    "            frequencies = np.cumsum(frequencies[:0:-1])[::-1]\n",
    "            for regression_index, value in enumerate(frequencies):\n",
    "                if value == 1:\n",
    "                    break\n",
    "            else:\n",
    "                continue\n",
    "            if regression_index < 2:\n",
    "                continue\n",
    "            max_count = (len(frequencies) - 1)\n",
    "            regression_constant = np.log(frequencies[0])\n",
    "            regression_slope = (np.log(frequencies[regression_index]) - regression_constant) / regression_index\n",
    "            score = regression_constant + regression_slope * max_count\n",
    "            if score < 0:\n",
    "                score_results[current_i] = score\n",
    "                hit_index = np.flatnonzero(local_candidates == max_count + 1)[0]\n",
    "                fragment = peptide_low + hit_index\n",
    "                fragment_results[current_i] = fragment\n",
    "                index_results[current_i] = ion_index\n",
    "                count_results[current_i] = max_count\n",
    "                current_i += 1\n",
    "    return (\n",
    "        score_results[:current_i],\n",
    "        fragment_results[:current_i],\n",
    "        index_results[:current_i],\n",
    "        count_results[:current_i]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores, fragments, ion_indices, count_results = calculate_scores(\n",
    "# #     queries=np.arange(spec_indptr.shape[0] - 1),\n",
    "#     queries=np.arange(100),\n",
    "#     spec_indptr=spec_indptr,\n",
    "#     low_limits=low_limits,\n",
    "#     high_limits=high_limits,\n",
    "#     peptide_count=len(peptide_sequences),\n",
    "#     peptide_pointers=peptide_pointers,\n",
    "# )\n",
    "# peptides = peptide_pointers[fragments]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with multiprocessing.pool.ThreadPool(thread_count) as p:\n",
    "    results = p.starmap(\n",
    "        annotate_mgf,\n",
    "        [\n",
    "            (\n",
    "                np.arange(i, spec_indptr.shape[0] - 1, thread_count),\n",
    "                spec_indptr,\n",
    "                low_limits,\n",
    "                high_limits,\n",
    "                len(peptide_sequences),\n",
    "                peptide_pointers,\n",
    "            ) for i in range(thread_count)\n",
    "        ]\n",
    "    )\n",
    "scores = np.concatenate([r[0] for r in results])\n",
    "fragments = np.concatenate([r[1] for r in results])\n",
    "ion_indices = np.concatenate([r[2] for r in results])\n",
    "count_results = np.concatenate([r[3] for r in results])\n",
    "del results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peptides = peptide_pointers[fragments]\n",
    "target_scores = scores[~decoys[peptides]]\n",
    "decoy_scores = scores[decoys[peptides]]\n",
    "scores, peptides, target_scores.shape, decoy_scores.shape\n",
    "score_cutoff = -5\n",
    "ts = np.sum(target_scores < score_cutoff)\n",
    "ds = np.sum(decoy_scores < score_cutoff)\n",
    "ts, ds, 1-ts/(ts+ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = np.unique(peptides[(scores < score_cutoff) & (~decoys[peptides])], return_counts=True)\n",
    "for i in zip(peptide_sequences[a], peptide_modifications[a], b):\n",
    "    print(i)\n",
    "# for i in np.unique(peptide_sequences[a]):\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "def export_annotated_csv(\n",
    "    scores,\n",
    "    fragments,\n",
    "    ion_indices,\n",
    "    spectra,\n",
    "    spec_indptr,\n",
    "    decoys,\n",
    "    peptide_sequences,\n",
    "    peptide_modifications,\n",
    "    score_cutoff,\n",
    "    proteins,\n",
    "    self_mzs,\n",
    "    self_ints,\n",
    "    file_name,\n",
    "    db,\n",
    "    peptide_pointers,\n",
    "    count_results,\n",
    "):\n",
    "    peptides = peptide_pointers[fragments]\n",
    "    selection = np.flatnonzero((scores < score_cutoff) & (~decoys[peptides]))\n",
    "    fragment_ion_numbers = db.get_fragment_coordinates(\"ionnumber\")\n",
    "    fragment_is_y_ion = db.get_fragment_coordinates(\"y_ion\")\n",
    "    spectrum_indices1 = np.searchsorted(\n",
    "        spec_indptr,\n",
    "        ion_indices,\n",
    "        \"right\"\n",
    "    ) - 1\n",
    "    with open(file_name, \"w\") as raw_outfile:\n",
    "        outfile = csv.writer(raw_outfile)\n",
    "        header = [\n",
    "            \"Fragment_index\",\n",
    "            \"Fragment_mz\",\n",
    "            \"Fragment_int\",\n",
    "            \"Fragment_ion_number\",\n",
    "            \"Fragment_is_y_ion\",\n",
    "            \"Spectrum_title\",\n",
    "            \"Peptide_sequence\",\n",
    "            \"peptide_mods\",\n",
    "            \"Score\",\n",
    "            \"Count\",\n",
    "#             \"Protein\",\n",
    "        ]\n",
    "        outfile.writerow(header)\n",
    "        for i in selection:\n",
    "            ion_index = ion_indices[i]\n",
    "            fragment_index = fragments[i]\n",
    "            peptide_index = peptides[i]\n",
    "            spectrum_index = spectrum_indices1[i]\n",
    "            row = [\n",
    "                ion_index,\n",
    "                self_mzs[ion_index],\n",
    "                self_ints[ion_index],\n",
    "                fragment_ion_numbers[fragment_index],\n",
    "                fragment_is_y_ion[fragment_index],\n",
    "                spectra[spectrum_index]['params']['title'],\n",
    "                peptide_sequences[peptide_index],\n",
    "                peptide_modifications[peptide_index],\n",
    "                scores[i],\n",
    "                count_results[i],\n",
    "            ]\n",
    "            outfile.writerow(row)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_annotated_csv(\n",
    "    scores=scores,\n",
    "    fragments=fragments,\n",
    "    ion_indices=ion_indices,\n",
    "    spectra=spectra,\n",
    "    spec_indptr=spec_indptr,\n",
    "    decoys=decoys,\n",
    "    peptide_sequences=peptide_sequences,\n",
    "    peptide_modifications=peptide_modifications,\n",
    "    score_cutoff=-5,\n",
    "    proteins=None,\n",
    "    self_mzs=self_mzs,\n",
    "    self_ints=self_ints,\n",
    "    file_name=\"/home/sander/Downloads/result_UnicityF.csv\",\n",
    "    db=db,\n",
    "    peptide_pointers=peptide_pointers,\n",
    "    count_results=count_results,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "plt.plot(\n",
    "    np.percentile(target_scores, range(101)),\n",
    "    range(101)\n",
    "#     *np.unique(\n",
    "#         np.round(target_scores, 1),\n",
    "#         return_counts=True\n",
    "#     )\n",
    ")\n",
    "plt.plot(\n",
    "    np.percentile(decoy_scores, range(101)),\n",
    "    range(101)\n",
    "#     *np.unique(\n",
    "#         np.round(decoy_scores, 1),\n",
    "#         return_counts=True\n",
    "#     )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxi=1000\n",
    "queries = range(maxi)\n",
    "count = 0\n",
    "for s in queries:\n",
    "    count += spec_indptr[s + 1] - spec_indptr[s]\n",
    "queries = iter(range(maxi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peptide_count = len(peptide_sequences),\n",
    "while True:\n",
    "    spectrum_index = next(queries)\n",
    "    if True:\n",
    "        spectrum_start = spec_indptr[spectrum_index]\n",
    "        spectrum_end = spec_indptr[spectrum_index + 1]\n",
    "        candidates = np.zeros(peptide_count, np.int64)\n",
    "        for ion_index in range(spectrum_start, spectrum_end):\n",
    "            peptide_low = low_limits[ion_index]\n",
    "            peptide_high = high_limits[ion_index]\n",
    "            if peptide_low == peptide_high:\n",
    "                continue\n",
    "            peptides = peptide_pointers[peptide_low: peptide_high]\n",
    "            candidates[peptides] += 1\n",
    "        for ion_index in range(spectrum_start, spectrum_end):\n",
    "            peptide_low = low_limits[ion_index]\n",
    "            peptide_high = high_limits[ion_index]\n",
    "            if peptide_low == peptide_high:\n",
    "                continue\n",
    "            peptides = peptide_pointers[peptide_low: peptide_high]\n",
    "            local_candidates = candidates[peptides]\n",
    "            frequencies = np.bincount(local_candidates)\n",
    "            frequencies = np.cumsum(frequencies[:0:-1])[::-1]\n",
    "            for regression_index, value in enumerate(frequencies):\n",
    "                if value == 1:\n",
    "                    break\n",
    "            else:\n",
    "                continue\n",
    "            if regression_index < 2:\n",
    "                continue\n",
    "            max_count = (len(frequencies) - 1)\n",
    "            regression_constant = np.log(frequencies[0])\n",
    "            regression_slope = (np.log(frequencies[regression_index]) - regression_constant) / regression_index\n",
    "            score = regression_constant + regression_slope * max_count\n",
    "            if score < 0:\n",
    "                score_results[current_i] = score\n",
    "                hit_index = np.flatnonzero(local_candidates == max_count + 1)[0]\n",
    "                fragment = peptide_low + hit_index\n",
    "                fragment_results[current_i] = fragment\n",
    "                index_results[current_i] = ion_index\n",
    "                current_i += 1\n",
    "                break\n",
    "        else:\n",
    "            continue\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "# plt.plot(np.diff(frequencies[::-1])[::-1], marker=\".\")\n",
    "plt.plot(np.log(frequencies), marker=\".\")\n",
    "plt.plot([0, max_count], [regression_constant, score])\n",
    "\n",
    "# for ion_index in range(start, end):\n",
    "#     peps = peptide_pointers[low_limits[ion_index]: high_limits[ion_index]]\n",
    "#     frequencies = np.bincount(candidates[peps])\n",
    "#     frequencies = np.cumsum(frequencies[:0:-1])[::-1]\n",
    "#     if (len(frequencies) < 2):\n",
    "#         continue\n",
    "#     if (frequencies[-1] != 1):\n",
    "#         plt.plot(np.log(frequencies), marker=\".\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectra[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ion_networks]",
   "language": "python",
   "name": "conda-env-ion_networks-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
