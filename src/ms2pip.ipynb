{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ms2pip.ms2pipC\n",
    "import ms2pip.retention_time\n",
    "import pyteomics.parser\n",
    "import pyteomics.fasta\n",
    "import h5py\n",
    "\n",
    "\n",
    "def read_proteins_and_peptides_from_fasta(\n",
    "    file_name,\n",
    "    protease,\n",
    "    missed_cleavages,\n",
    "    min_peptide_length,\n",
    "    max_peptide_length,\n",
    "    standard_amino_acids,\n",
    "    reversed_protein_decoy,\n",
    "):\n",
    "    print(f\"Reading {file_name}\")\n",
    "    fasta_file = pyteomics.fasta.FASTA(file_name)\n",
    "    proteins = {}\n",
    "    peptides = {}\n",
    "    for protein_index, (description, sequence) in enumerate(fasta_file):\n",
    "        protein_info = pyteomics.fasta.parse(description)\n",
    "        protein = protein_info[\"entry\"]\n",
    "        del protein_info[\"entry\"]\n",
    "        if reversed_protein_decoy:\n",
    "            protein = f\"DECOY_{protein}\"\n",
    "            sequence = sequence[::-1]\n",
    "        protein_info[\"sequence\"] = sequence\n",
    "        protein_info[\"index\"] = protein_index\n",
    "        proteins[protein] = protein_info\n",
    "        for peptide in pyteomics.parser.cleave(\n",
    "            sequence,\n",
    "            pyteomics.parser.expasy_rules[protease],\n",
    "            missed_cleavages\n",
    "        ):\n",
    "            if not (min_peptide_length < len(peptide) < max_peptide_length):\n",
    "                continue\n",
    "            if standard_amino_acids:\n",
    "                if len(set(peptide) - set(\"ARNDBCEQZGHILKMFPSTWYV\")) != 0:\n",
    "                    continue\n",
    "            if peptide not in peptides:\n",
    "                peptides[peptide] = []\n",
    "            peptides[peptide].append(protein_index)\n",
    "    return proteins, peptides\n",
    "\n",
    "\n",
    "def peptide_dict_to_peprec(\n",
    "    peptides,\n",
    "    variable_ptms,\n",
    "    fixed_ptms,\n",
    "    ptm_dict\n",
    "):\n",
    "    print(f\"Creating peprec\")\n",
    "    peptide_list = [\n",
    "        (\n",
    "            peptide,\n",
    "            \";\".join([str(p) for p in protein_list])\n",
    "        ) for (peptide, protein_list) in peptides.items()\n",
    "    ]\n",
    "    columns = [\n",
    "        \"peptide\",\n",
    "        \"proteins\",\n",
    "    ]\n",
    "    if (len(variable_ptms) + len(fixed_ptms)) > 0:\n",
    "        columns += [\"modifications\"]\n",
    "        modified_peptide_list = []\n",
    "        for peptide, proteins in peptide_list:\n",
    "            for ptm_combination in generate_ptm_combinations(\n",
    "                f\".{peptide}.\",\n",
    "                [[]] * (len(peptide) + 2),\n",
    "                variable_ptms,\n",
    "                fixed_ptms,\n",
    "                static_ptms=False\n",
    "            ):\n",
    "                parsed_ptm_combination = \"|\".join(\n",
    "                    [\n",
    "                        f\"{i}|{ptm_dict[ptm][0]}\" for i, ptm in enumerate(ptm_combination) if ptm != \"\"\n",
    "                    ]\n",
    "                )\n",
    "                if parsed_ptm_combination == \"\":\n",
    "                    parsed_ptm_combination = \"-\"\n",
    "                modified_peptide_list.append(\n",
    "                    (peptide, proteins, parsed_ptm_combination)\n",
    "                ) \n",
    "        peptide_list = modified_peptide_list\n",
    "    peprec = pd.DataFrame(\n",
    "        peptide_list,\n",
    "        columns=columns\n",
    "    )\n",
    "    peprec[\"index\"] = np.arange(peprec.shape[0])\n",
    "    peprec.set_index(\"index\", inplace=True)\n",
    "    return peprec\n",
    "\n",
    "\n",
    "def protein_dict_to_protrec(proteins):\n",
    "    print(f\"Creating protrec\")\n",
    "    columns = sorted(next(iter(proteins.values())))\n",
    "    protrec = pd.DataFrame(\n",
    "        [\n",
    "            tuple(\n",
    "                [protein_name] + [\n",
    "                    protein_info[column] if column in protein_info else \"\" for column in columns\n",
    "                ]\n",
    "            ) for protein_name, protein_info in sorted(\n",
    "                proteins.items(),\n",
    "                key=lambda p: p[1][\"index\"]\n",
    "            )\n",
    "        ],\n",
    "        columns=[\"protein\"] + columns\n",
    "    )\n",
    "    protrec.set_index(\"index\", inplace=True)\n",
    "    return protrec\n",
    "\n",
    "\n",
    "def predict_fragrec(\n",
    "    peprec,\n",
    "    model,\n",
    "    cpu_count,\n",
    "    charges,\n",
    "    ptm_dict,\n",
    "    modifications,\n",
    "):\n",
    "    print(f\"Predicting fragrec\")\n",
    "    ms2pip_params = {\n",
    "        \"ms2pip\": {\n",
    "            \"model\": model,\n",
    "            \"frag_error\": 0,\n",
    "            \"ptm\": [\n",
    "                \",\".join([str(s) for s in ptm_values]) for ptm_values in ptm_dict.values()\n",
    "            ],\n",
    "            \"sptm\": [],\n",
    "            \"gptm\": [],\n",
    "        }\n",
    "    }\n",
    "    for charge in charges:\n",
    "        charged_peprec = peprec[[\"peptide\"]].copy()\n",
    "        charged_peprec[\"spec_id\"] = peprec.index\n",
    "        charged_peprec[\"charge\"] = charge\n",
    "        if not modifications:\n",
    "            charged_peprec[\"modifications\"] = \"-\"\n",
    "        else:\n",
    "            charged_peprec[\"modifications\"] = peprec[\"modifications\"]\n",
    "        charged_fragrec = ms2pip.ms2pipC.MS2PIP(\n",
    "            charged_peprec,\n",
    "            num_cpu=cpu_count,\n",
    "            params=ms2pip_params,\n",
    "            return_results=True,\n",
    "        ).run()\n",
    "        del charged_fragrec[\"charge\"]\n",
    "        charged_fragrec.set_index([\"spec_id\", \"ion\", \"ionnumber\", \"mz\"], inplace=True)\n",
    "        try:\n",
    "            fragrec = fragrec.join(charged_fragrec)\n",
    "            fragrec.rename(\n",
    "                columns={'prediction': f'prediction_charge_{charge}'},\n",
    "                inplace=True\n",
    "            )\n",
    "        except NameError:\n",
    "            fragrec = charged_fragrec.rename(\n",
    "                columns={'prediction': f'prediction_charge_{charge}'}\n",
    "            )\n",
    "    fragrec.reset_index(inplace=True)\n",
    "    fragrec.sort_values(by=\"mz\", inplace=True)\n",
    "    fragrec.rename(\n",
    "        columns={'spec_id': f'peptide_index'},\n",
    "        inplace=True\n",
    "    )\n",
    "    fragrec[\"b_ion\"] = fragrec[\"ion\"]==\"B\"\n",
    "    fragrec[\"y_ion\"] = fragrec[\"ion\"]==\"Y\"\n",
    "    del fragrec[\"ion\"]\n",
    "    fragrec[\"index\"] = np.arange(fragrec.shape[0])\n",
    "    fragrec.set_index(\"index\", inplace=True)\n",
    "    return fragrec\n",
    "\n",
    "\n",
    "def predict_rts(\n",
    "    peprec,\n",
    "    modifications\n",
    "):\n",
    "    print(f\"Predicting rts\")\n",
    "    rt_peprec = peprec[[\"peptide\"]]\n",
    "    if not modifications:\n",
    "        rt_peprec[\"modifications\"] = \"-\"\n",
    "    else:\n",
    "        rt_peprec[\"modifications\"] = peprec[\"modifications\"]\n",
    "    ms2pip.retention_time.RetentionTime().add_rt_predictions(rt_peprec)\n",
    "    rts = rt_peprec[\"rt\"].values\n",
    "#     batch_size = 10**5\n",
    "#     rts = []\n",
    "#     for i in range(0, peprec.shape[0], batch_size):\n",
    "#         tmp = peprec[[\"peptide\", \"modifications\"]][i:i + batch_size]\n",
    "#         ms2pip.retention_time.RetentionTime().add_rt_predictions(tmp)\n",
    "#         rts.append(tmp[\"rt\"])\n",
    "#     rts = np.concatenate(rts)\n",
    "    return rts\n",
    "\n",
    "\n",
    "def write_hdf_file(file_name, data):\n",
    "    with h5py.File(file_name, \"w\") as hdf_file:\n",
    "        for column in data.columns:\n",
    "            try:\n",
    "                hdf_file.create_dataset(\n",
    "                    column,\n",
    "                    data=data[column],\n",
    "                    compression=\"lzf\",\n",
    "                )\n",
    "            except TypeError:\n",
    "                hdf_file.create_dataset(\n",
    "                    column,\n",
    "                    data=data[column],\n",
    "                    compression=\"lzf\",\n",
    "                    dtype=h5py.string_dtype()\n",
    "                )\n",
    "\n",
    "                \n",
    "def generate_ptm_combinations_recursively(ptms, selected=[]):\n",
    "    if len(selected) == len(ptms):\n",
    "        yield selected\n",
    "    else:\n",
    "        for ptm in ptms[len(selected)]:\n",
    "            for ptm_combination in generate_ptm_combinations_recursively(\n",
    "                ptms,\n",
    "                selected + [ptm]\n",
    "            ):\n",
    "                yield ptm_combination\n",
    "\n",
    "\n",
    "def generate_ptm_combinations(\n",
    "    sequence,\n",
    "    ptms,\n",
    "    variable_ptms,\n",
    "    fixed_ptms,\n",
    "    static_ptms=False\n",
    "):\n",
    "    local_ptms = [[] for i in sequence]\n",
    "    if sequence[0] == \"n\":\n",
    "        local_ptms[0] += ptms[0]\n",
    "    if sequence[-1] == \"c\":\n",
    "        local_ptms[-1] = ptms[-1]\n",
    "    for i, ptm in enumerate(ptms[1:-1]):\n",
    "        local_ptms[i + 1] += ptm\n",
    "    for i, aa in enumerate(f\"n{sequence[1:-1]}c\"):\n",
    "        if (not static_ptms) or (len(local_ptms[i]) == 0):\n",
    "            if aa in variable_ptms:\n",
    "                local_ptms[i] += variable_ptms[aa]\n",
    "            if aa in fixed_ptms:\n",
    "                local_ptms[i] += fixed_ptms[aa]\n",
    "            else:\n",
    "                local_ptms[i].append(\"\")\n",
    "    for ptm_combination in generate_ptm_combinations_recursively(local_ptms):\n",
    "        yield ptm_combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasta_file_name = \"/home/sander/Documents/Proteomics/data/databases/ecoli.fasta\"\n",
    "\n",
    "protrec_file_name = \"/home/sander/Documents/Proteomics/data/databases/ecoli_proteins.hdf\"\n",
    "peprec_file_name = \"/home/sander/Documents/Proteomics/data/databases/ecoli_peptides.hdf\"\n",
    "fragrec_file_name = \"/home/sander/Documents/Proteomics/data/databases/ecoli_fragments.hdf\"\n",
    "\n",
    "variable_ptms = {\n",
    "    \"M\": [\"M_ox\"],\n",
    "#     \"n\": [\"n_ac\"],\n",
    "}\n",
    "\n",
    "fixed_ptms = {\n",
    "    \"C\": [\"C_cam\"]\n",
    "}\n",
    "\n",
    "ptm_dict = {\n",
    "    \"C_cam\": (\"Oxidation\" , 15.9994, \"opt\", \"M\"),\n",
    "    \"M_ox\": (\"Carbamidomethyl\" , 57.0513, \"opt\", \"C\"),\n",
    "    \"N_ac\": (\"Acetyl\" , 42.0106, \"opt\", \"N-term\"),\n",
    "}\n",
    "    \n",
    "    \n",
    "model = \"HCD\"\n",
    "protease = \"trypsin\"\n",
    "missed_cleavages = 0\n",
    "min_peptide_length = 6\n",
    "max_peptide_length = 30\n",
    "standard_amino_acids = True\n",
    "reversed_protein_decoy = False\n",
    "charges = [2, 3]\n",
    "cpu_count = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading /home/sander/Documents/Proteomics/data/databases/ecoli.fasta\n",
      "Creating protrec\n",
      "Creating peprec\n",
      "Predicting fragrec\n",
      "(0)500 (3)500 (2)500 (5)500 (4)500 (1)500 (7)500 (6)500 (0)1000 (4)1000 (2)1000 (3)1000 (5)1000 (7)1000 (1)1000 (6)1000 (4)1500 (2)1500 (0)1500 (7)1500 (5)1500 (3)1500 (1)1500 (6)1500 (4)2000 (2)2000 (0)2000 (7)2000 (3)2000 (5)2000 (6)2000 (1)2000 (2)2500 (0)2500 (4)2500 (7)2500 (3)2500 (5)2500 (6)2500 (1)2500 (2)3000 (7)3000 (3)3000 (4)3000 (0)3000 (5)3000 (6)3000 (2)3500 (1)3000 (3)3500 (7)3500 (0)3500 (4)3500 (2)4000 (6)3500 (5)3500 (3)4000 (1)3500 (0)4000 (4)4000 (7)4000 (6)4000 (2)4500 (5)4000 (3)4500 (1)4000 (4)4500 (7)4500 (0)4500 (6)4500 (5)4500 (3)5000 (2)5000 (4)5000 (1)4500 (0)5000 (7)5000 (3)5500 (6)5000 (5)5000 (2)5500 (4)5500 (0)5500 (7)5500 (1)5000 (3)6000 (6)5500 (5)5500 (0)6000 (2)6000 (4)6000 (7)6000 (1)5500 (3)6500 (6)6000 (7)6500 (2)6500 (4)6500 (0)6500 (5)6000 (1)6000 (6)6500 (3)7000 (2)7000 (7)7000 (4)7000 (5)6500 (0)7000 (1)6500 (3)7500 (6)7000 (2)7500 (7)7500 (4)7500 (5)7000 (0)7500 (1)7000 (7)8000 (6)7500 (2)8000 (3)8000 (4)8000 (0)8000 (5)7500 (2)8500 (3)8500 (1)7500 (7)8500 (4)8500 (6)8000 (0)8500 (5)8000 (3)9000 (2)9000 (7)9000 (1)8000 (4)9000 (0)9000 (6)8500 (5)8500 (3)9500 (4)9500 (7)9500 (1)8500 (2)9500 (6)9000 (5)9000 (0)9500 (3)10000 (4)10000 (7)10000 (2)10000 (1)9000 (6)9500 (0)10000 (3)10500 (5)9500 (4)10500 (7)10500 (6)10000 (2)10500 (0)10500 (1)9500 (4)11000 (5)10000 (7)11000 (3)11000 (6)10500 (2)11000 (0)11000 (1)10000 (5)10500 (6)11000 (1)10500 (5)11000 (1)11000 \n",
      "(1)500 (0)500 (3)500 (2)500 (4)500 (6)500 (7)500 (5)500 (1)1000 (0)1000 (2)1000 (4)1000 (6)1000 (3)1000 (5)1000 (7)1000 (0)1500 (2)1500 (1)1500 (5)1500 (7)1500 (6)1500 (3)1500 (4)1500 (2)2000 (0)2000 (1)2000 (5)2000 (7)2000 (6)2000 (3)2000 (4)2000 (2)2500 (5)2500 (1)2500 (7)2500 (0)2500 (6)2500 (3)2500 (4)2500 (2)3000 (5)3000 (7)3000 (6)3000 (0)3000 (1)3000 (3)3000 (4)3000 (2)3500 (5)3500 (7)3500 (6)3500 (0)3500 (1)3500 (3)3500 (4)3500 (2)4000 (5)4000 (7)4000 (0)4000 (6)4000 (4)4000 (1)4000 (3)4000 (2)4500 (5)4500 (7)4500 (0)4500 (6)4500 (4)4500 (2)5000 (3)4500 (5)5000 (1)4500 (7)5000 (0)5000 (4)5000 (6)5000 (2)5500 (5)5500 (3)5000 (7)5500 (1)5000 (0)5500 (4)5500 (2)6000 (6)5500 (3)5500 (5)6000 (7)6000 (4)6000 (1)5500 (0)6000 (6)6000 (2)6500 (5)6500 (3)6000 (4)6500 (7)6500 (0)6500 (1)6000 (2)7000 (6)6500 (5)7000 (4)7000 (3)6500 (7)7000 (0)7000 (6)7000 (1)6500 (2)7500 (4)7500 (7)7500 (5)7500 (3)7000 (6)7500 (0)7500 (1)7000 (2)8000 (7)8000 (4)8000 (5)8000 (3)7500 (6)8000 (0)8000 (1)7500 (2)8500 (5)8500 (3)8000 (7)8500 (4)8500 (0)8500 (6)8500 (1)8000 (2)9000 (5)9000 (4)9000 (7)9000 (3)8500 (6)9000 (0)9000 (1)8500 (2)9500 (5)9500 (3)9000 (4)9500 (0)9500 (7)9500 (1)9000 (6)9500 (2)10000 (5)10000 (3)9500 (0)10000 (7)10000 (4)10000 (6)10000 (1)9500 (3)10000 (5)10500 (2)10500 (7)10500 (6)10500 (0)10500 (4)10500 (1)10000 (3)10500 (5)11000 (2)11000 (6)11000 (7)11000 (0)11000 (3)11000 (1)10500 (4)11000 (1)11000 \n"
     ]
    }
   ],
   "source": [
    "modifications = (len(variable_ptms) + len(fixed_ptms)) > 0\n",
    "proteins, peptides = read_proteins_and_peptides_from_fasta(\n",
    "    fasta_file_name,\n",
    "    protease,\n",
    "    missed_cleavages,\n",
    "    min_peptide_length,\n",
    "    max_peptide_length,\n",
    "    standard_amino_acids,\n",
    "    reversed_protein_decoy\n",
    ")\n",
    "protrec = protein_dict_to_protrec(proteins)\n",
    "peprec = peptide_dict_to_peprec(\n",
    "    peptides,\n",
    "    variable_ptms,\n",
    "    fixed_ptms,\n",
    "    ptm_dict\n",
    ")\n",
    "# peprec[\"rt\"] = predict_rts(peprec, modifications)\n",
    "fragrec = predict_fragrec(\n",
    "    peprec,\n",
    "    model,\n",
    "    cpu_count,\n",
    "    charges,\n",
    "    ptm_dict,\n",
    "    modifications\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_hdf_file(protrec_file_name, protrec)\n",
    "write_hdf_file(peprec_file_name, peprec)\n",
    "write_hdf_file(fragrec_file_name, fragrec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:compomics]",
   "language": "python",
   "name": "conda-env-compomics-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
