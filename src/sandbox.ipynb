{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import importlib\n",
    "from timeit import timeit\n",
    "import logging\n",
    "import sys\n",
    "import importlib\n",
    "import time\n",
    "import multiprocessing as mp\n",
    "import multiprocessing.pool\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import h5py\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import numba\n",
    "import sklearn.linear_model\n",
    "\n",
    "import ms_utils\n",
    "import browser\n",
    "import interface\n",
    "import ms_database\n",
    "import ms_run_files\n",
    "\n",
    "import sandbox\n",
    "\n",
    "import line_profiler\n",
    "profile = line_profiler.LineProfiler()\n",
    "# heat.evolve = profile(heat.evolve)\n",
    "# profile.print_stats()\n",
    "\n",
    "def reload():\n",
    "    importlib.reload(ms_run_files)\n",
    "    importlib.reload(ms_utils)\n",
    "    importlib.reload(browser)\n",
    "    importlib.reload(interface)\n",
    "    importlib.reload(sandbox)\n",
    "    importlib.reload(ms_database)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mz1 = pd.read_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload()\n",
    "self = ms_run_files.Evidence(\"/home/sander/Documents/Proteomics/data/ecoli_test/28Oct2016_060.inet.hdf\")\n",
    "other = ms_run_files.Evidence(\"/home/sander/Documents/Proteomics/data/ecoli_test/28Oct2016_061.inet.hdf\")\n",
    "inet1 = self.ion_network\n",
    "inet2 = other.ion_network\n",
    "fint1, fmz1, pmz1, prt1 = inet1.get_ion_coordinates()\n",
    "fint2, fmz2, pmz2, prt2 = inet2.get_ion_coordinates()\n",
    "parameters = {\n",
    "    \"log_file_name\": \"log.txt\",\n",
    "    \"output_directory\": \"\",\n",
    "    \"force_overwrite\": True,\n",
    "    \"threads\": 8,\n",
    "    \"fragment_errors\": {\n",
    "        \"FRAGMENT_MZ\": 50.0,\n",
    "        \"PRECURSOR_RT\": 0.5,\n",
    "        \"PRECURSOR_DT\": 2.0,\n",
    "        \"PRECURSOR_MZ\": 5.0\n",
    "    },\n",
    "    \"calibrate_PRECURSOR_RT\": True,\n",
    "    \"calibration_ppm_FRAGMENT_MZ\": 1.0,\n",
    "    \"calibration_ions\": 50000\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ali1 = self.get_aligned_nodes_from_group(\n",
    "    other=other,\n",
    "    return_as_mask=False,\n",
    "    kind=\"unique\",\n",
    "    symmetric=False\n",
    ")\n",
    "ali2 = other.get_aligned_nodes_from_group(\n",
    "    other=self,\n",
    "    return_as_mask=False,\n",
    "    kind=\"unique\",\n",
    "    symmetric=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"A\": 71.037114,\n",
    "# \"R\": 156.101111,\n",
    "# \"N\": 114.042927,\n",
    "# \"D\": 115.026943,\n",
    "# \"C\": 103.009185,\n",
    "# \"E\": 129.042593,\n",
    "# \"Q\": 128.058578,\n",
    "# \"G\": 57.021464,\n",
    "# \"H\": 137.058912,\n",
    "# \"I\": 113.084064,\n",
    "# \"L\": 113.084064,\n",
    "# \"K\": 128.094963,\n",
    "# \"M\": 131.040485,\n",
    "# \"F\": 147.068414,\n",
    "# \"P\": 97.052764,\n",
    "# \"S\": 87.032028,\n",
    "# \"T\": 101.047679,\n",
    "# \"U\": 144.95959,\n",
    "# \"W\": 186.079313,\n",
    "# \"Y\": 163.063329,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __tune_precursor_errors(\n",
    "    self,\n",
    "    to_select_per_sample,\n",
    "    ppm=10,\n",
    "    calibration_prior_estimates={\n",
    "        \"PRECURSOR_RT\": 0.5,\n",
    "        \"PRECURSOR_MZ\": 5,\n",
    "    },\n",
    "    mz_distance=113.084064,\n",
    "    min_window=100,\n",
    "    usable=(0.1, 0.5),\n",
    "):\n",
    "    estimations = {}\n",
    "    selected_indices = np.argpartition(\n",
    "        self.get_ion_coordinates(\"FRAGMENT_LOGINT\"),\n",
    "        - to_select_per_sample\n",
    "    )[-to_select_per_sample:]\n",
    "    fragment_mzs = self.get_ion_coordinates(\"FRAGMENT_MZ\")\n",
    "    selected_indices = selected_indices[\n",
    "        np.argsort(fragment_mzs[selected_indices])\n",
    "    ]\n",
    "    fragment_mzs = fragment_mzs[selected_indices]\n",
    "    lower_limits = np.searchsorted(\n",
    "        fragment_mzs,\n",
    "        (fragment_mzs + mz_distance) / (1 + ppm * 10**-6),\n",
    "        \"left\"\n",
    "    )\n",
    "    upper_limits = np.searchsorted(\n",
    "        fragment_mzs,\n",
    "        (fragment_mzs + mz_distance) * (1 + ppm * 10**-6),\n",
    "        \"right\"\n",
    "    )\n",
    "    indptr = np.zeros(self.node_count + 1, np.int64)\n",
    "    indptr[selected_indices + 1] = upper_limits - lower_limits\n",
    "    indptr = np.cumsum(indptr)\n",
    "    order = np.argsort(selected_indices)\n",
    "    indices = np.concatenate(\n",
    "        [\n",
    "            selected_indices[low: high] for low, high in zip(\n",
    "                lower_limits[order],\n",
    "                upper_limits[order]\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    use_slice = slice(\n",
    "        int(indices.shape[0] * usable[0]),\n",
    "        int(indices.shape[0] * usable[1])\n",
    "    )\n",
    "    for dimension in self.precursor_dimensions:\n",
    "        precursor_array = self.get_ion_coordinates(dimension)\n",
    "        precursor_differences = np.sort(\n",
    "            np.abs(\n",
    "                np.repeat(\n",
    "                    precursor_array,\n",
    "                    np.diff(indptr)\n",
    "                ) - precursor_array[indices]\n",
    "            )\n",
    "        )\n",
    "        bandwidth = np.max(\n",
    "            precursor_differences[use_slice][min_window:] - precursor_differences[use_slice][:-min_window]\n",
    "        )\n",
    "        frequency = np.searchsorted(\n",
    "            precursor_differences,\n",
    "            precursor_differences + bandwidth\n",
    "        ) - np.searchsorted(\n",
    "            precursor_differences,\n",
    "            precursor_differences - bandwidth\n",
    "        )     \n",
    "        ransac_regressor = sklearn.linear_model.RANSACRegressor()\n",
    "        ransac_regressor.fit(\n",
    "            precursor_differences[use_slice].reshape(-1, 1),\n",
    "            frequency[use_slice].reshape(-1, 1),\n",
    "        )\n",
    "        min_index = np.argmin(\n",
    "            ransac_regressor.predict(\n",
    "                precursor_differences.reshape(-1, 1)\n",
    "            ).flatten() < frequency\n",
    "        )\n",
    "        estimations[dimension] = precursor_differences[min_index]\n",
    "        \n",
    "        if True:\n",
    "            decimals = int(np.floor(-np.log10(bandwidth)))\n",
    "            print(decimals)\n",
    "            plt.plot(precursor_differences, frequency)\n",
    "#             precursor_differences1, frequency1 = np.unique(\n",
    "#                 np.round(precursor_differences, decimals),\n",
    "#                 return_counts=True\n",
    "#             )\n",
    "# #             plt.plot(precursor_differences1, frequency1)\n",
    "#             max_ = np.max(precursor_differences)\n",
    "#             size = max_*10**decimals\n",
    "#             precursor_differences2 = np.linspace(\n",
    "#                 0,\n",
    "#                 np.max(precursor_differences1),\n",
    "#                 size+1\n",
    "#             )\n",
    "#             frequency2 = np.bincount(\n",
    "#                 (precursor_differences * 10**decimals).astype(np.int)\n",
    "#             )\n",
    "#             plt.plot(precursor_differences2, frequency2)\n",
    "#             ransac_regressor = sklearn.linear_model.RANSACRegressor()\n",
    "#             ransac_regressor.fit(\n",
    "#                 precursor_differences2[slice(\n",
    "#                     int(size * usable[0]),\n",
    "#                     int(size * usable[1])\n",
    "#                 )].reshape(-1, 1),\n",
    "#                 frequency2[slice(\n",
    "#                     int(size * usable[0]),\n",
    "#                     int(size * usable[1])\n",
    "#                 )].reshape(-1, 1),\n",
    "#             )\n",
    "#             plt.plot(\n",
    "#                 precursor_differences2[slice(\n",
    "#                     int(size * usable[0]),\n",
    "#                     int(size * usable[1])\n",
    "#                 )],\n",
    "#                 frequency2[slice(\n",
    "#                     int(size * usable[0]),\n",
    "#                     int(size * usable[1])\n",
    "#                 )]\n",
    "#             )\n",
    "#             plt.plot(\n",
    "#                 precursor_differences2[[0,-1]],\n",
    "#                 ransac_regressor.predict(precursor_differences2[[0,-1]].reshape(-1, 1))\n",
    "#             )\n",
    "#             estimations[dimension] = precursor_differences[min_index]\n",
    "        \n",
    "    return estimations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "inet = ms_run_files.Network(\n",
    "    f\"/home/sander/Documents/Proteomics/data/ecoli_test/28Oct2016_060.inet.hdf\"\n",
    ")\n",
    "\n",
    "estimations = __tune_precursor_errors(\n",
    "    inet,\n",
    "    to_select_per_sample = 100000,\n",
    "#     to_select_per_sample = inet.node_count // 10,\n",
    "#     to_select_per_sample = inet.node_count,\n",
    "    ppm = 10,\n",
    "    calibration_prior_estimates = {\n",
    "        \"PRECURSOR_RT\": 0.10909999999999798,\n",
    "        \"PRECURSOR_MZ\": 22.399999999999977,\n",
    "    },\n",
    ")\n",
    "print(estimations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "dimension = \"PRECURSOR_MZ\"\n",
    "# dimension = \"PRECURSOR_RT\"\n",
    "min_window = 100\n",
    "usable = (0.1, 0.5)\n",
    "x=np.sort(calibration_diffs[\"target\"][dimension])\n",
    "use_slice = slice(\n",
    "    int(x.shape[0]*usable[0]),\n",
    "    int(x.shape[0]*usable[1])\n",
    ")\n",
    "# offset = np.max(\n",
    "#     x[min_window:]-x[:-min_window]\n",
    "# )\n",
    "offset = np.max(\n",
    "    x[use_slice][min_window:]-x[use_slice][:-min_window]\n",
    ")\n",
    "# offset=0.001\n",
    "print(offset)\n",
    "l = np.searchsorted(x, x - offset)\n",
    "r = np.searchsorted(x, x)\n",
    "y = r-l\n",
    "x, y = x[l>0],y[l>0]\n",
    "# plt.plot(x,np.cumsum(y)/np.arange(y.shape[0]))\n",
    "plt.plot(x,y)\n",
    "ransac = sklearn.linear_model.RANSACRegressor()\n",
    "ransac.fit(\n",
    "    x[use_slice].reshape(-1, 1),\n",
    "    y[use_slice].reshape(-1, 1),\n",
    ")\n",
    "plt.plot(\n",
    "    x[[0,-1]],\n",
    "    ransac.predict(x[[0,-1]].reshape(-1, 1))\n",
    ")\n",
    "plt.plot(\n",
    "    x[use_slice],\n",
    "    y[use_slice]\n",
    ")\n",
    "min_index = np.argmin(\n",
    "    ransac.predict(x.reshape(-1, 1)).flatten() < y\n",
    ")\n",
    "plt.title(f\"{dimension}: {x[min_index]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib notebook\n",
    "\n",
    "# x, y = result_coordinates[\"PRECURSOR_MZ\"]\n",
    "# plt.plot(x, y)\n",
    "# plt.axhline(y[-1])\n",
    "# # plt.set_title(inet.run_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimension = \"PRECURSOR_MZ\"\n",
    "dimension = \"PRECURSOR_RT\"\n",
    "\n",
    "x = np.concatenate(\n",
    "    [\n",
    "        calibration_diffs[\"target\"][dimension],\n",
    "        calibration_diffs[\"decoy\"][dimension]\n",
    "    ]\n",
    ")\n",
    "y = np.repeat(\n",
    "    [\n",
    "        1,\n",
    "#         -calibration_diffs[\"target\"][dimension].shape[0] / calibration_diffs[\"decoy\"][dimension].shape[0]\n",
    "        -1\n",
    "    ],\n",
    "    [\n",
    "        calibration_diffs[\"target\"][dimension].shape[0],\n",
    "        calibration_diffs[\"decoy\"][dimension].shape[0]\n",
    "    ]\n",
    ")\n",
    "o = np.argsort(x)\n",
    "x = x[o]\n",
    "y = y[o]\n",
    "# y = np.cumsum(y)\n",
    "tps = np.cumsum(y==1)\n",
    "fps = np.cumsum(y==-1) * calibration_diffs[\"target\"][dimension].shape[0] / calibration_diffs[\"decoy\"][dimension].shape[0]\n",
    "# tps = tps[::-1]\n",
    "# fps = fps[::-1]\n",
    "\n",
    "max_index = np.argmax(tps-fps)\n",
    "ransac = sklearn.linear_model.RANSACRegressor()\n",
    "ransac.fit(\n",
    "    x[max_index:].reshape(-1, 1),\n",
    "    (tps-fps)[max_index:].reshape(-1, 1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b = np.unique(\n",
    "    np.round(calibration_diffs[\"target\"][dimension],1),\n",
    "    return_counts=True\n",
    ")\n",
    "# ransac = sklearn.linear_model.RANSACRegressor()\n",
    "# ransac.fit(\n",
    "#     a.reshape(-1, 1),\n",
    "#     b.reshape(-1, 1),\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.covariance import EllipticEnvelope\n",
    "# define a matrix\n",
    "X = np.stack(\n",
    "    [\n",
    "        calibration_diffs[\"target\"][\"PRECURSOR_RT\"]/0.1,\n",
    "        calibration_diffs[\"target\"][\"PRECURSOR_MZ\"]/5,\n",
    "    ]\n",
    ").T\n",
    "# cov = EllipticEnvelope(random_state=0).fit(X)\n",
    "import hdbscan\n",
    "clusterer = hdbscan.HDBSCAN()\n",
    "clusterer.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "plt.scatter(\n",
    "    calibration_diffs[\"target\"][\"PRECURSOR_RT\"],\n",
    "    calibration_diffs[\"target\"][\"PRECURSOR_MZ\"],\n",
    "    c=clusterer.labels_\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "# plt.plot(x, tps-fps)\n",
    "# # plt.plot(x, fps)\n",
    "# plt.plot(\n",
    "#     x[[0, -1]],\n",
    "#     ransac.predict(x[[0, -1]].reshape(-1, 1))\n",
    "# )\n",
    "# # plt.plot(x, np.arange(x.shape[0]))\n",
    "# plt.scatter(x[max_index], (tps-fps)[max_index], c=\"r\")\n",
    "# plt.title(f\"max: {x[max_index]:.3f}, {(tps-fps)[max_index]:.3f}\")\n",
    "\n",
    "# y = (tps-fps) - ransac.predict(x.reshape(-1, 1)).flatten()\n",
    "# max_index = np.flatnonzero(y>0)[0]\n",
    "# plt.plot(\n",
    "#     x,\n",
    "#     y\n",
    "# )\n",
    "# plt.scatter(x[max_index], y[max_index], c=\"r\")\n",
    "# plt.title(f\"max: {x[max_index]:.3f}, {y[max_index]:.3f}\")\n",
    "\n",
    "plt.plot(a, b)\n",
    "# plt.plot(\n",
    "#     a[[0, -1]],\n",
    "#     ransac.predict(a[[0, -1]].reshape(-1, 1))\n",
    "# )\n",
    "aa, bb = np.unique(\n",
    "        np.round(calibration_diffs[\"decoy\"][dimension],1),\n",
    "        return_counts=True\n",
    "    )\n",
    "plt.plot(aa, bb*calibration_diffs[\"target\"][dimension].shape[0]/calibration_diffs[\"decoy\"][dimension].shape[0])\n",
    "\n",
    "# y = tps - fps\n",
    "# z = np.cumsum(y)/np.arange(y.shape[0])\n",
    "# plt.plot(x,z)\n",
    "# tps1 = np.cumsum(tps)/np.arange(tps.shape[0])\n",
    "# fps1 = np.cumsum(fps)/np.arange(fps.shape[0])\n",
    "# plt.plot(x,tps1)\n",
    "# plt.plot(x,fps1)\n",
    "# plt.plot(x, tps1/(tps1+fps1))\n",
    "# plt.axhline(z[-1])\n",
    "# max_index = np.flatnonzero(z>z[-1])[0]\n",
    "# plt.title(f\"max: {x[max_index]:.3f}, {z[max_index]:.3f}\")\n",
    "\n",
    "# plt.plot(x,tps-fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "plt.plot(\n",
    "    np.sort(calibration_diffs[\"target\"][\"PRECURSOR_RT\"]),\n",
    "    np.linspace(0,1,calibration_diffs[\"target\"][\"PRECURSOR_RT\"].shape[0]),\n",
    ")\n",
    "plt.plot(\n",
    "    np.sort(calibration_diffs[\"decoy\"][\"PRECURSOR_RT\"]),\n",
    "    np.linspace(0,1,calibration_diffs[\"decoy\"][\"PRECURSOR_RT\"].shape[0]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib notebook\n",
    "\n",
    "\n",
    "sns.jointplot(\n",
    "    calibration_diffs[\"decoy\"][\"PRECURSOR_MZ\"],\n",
    "    calibration_diffs[\"decoy\"][\"PRECURSOR_RT\"],\n",
    "    kind=\"hex\",\n",
    "    gridsize=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %matplotlib notebook\n",
    "\n",
    "# options = [0.1, 0.5, 1, 5, 10, 50]\n",
    "# inets = [\n",
    "#     ms_run_files.Network(\n",
    "#         f\"/home/sander/Documents/Proteomics/data/ecoli_test/28Oct2016_06{i}.inet.hdf\"\n",
    "#     ) for i in range(0,10)\n",
    "# ]\n",
    "# fig, ax = plt.subplots(len(inets), 1)\n",
    "# for i, inet in enumerate(inets):\n",
    "#     for opt in options:\n",
    "#         result_coordinates, calibration_diffs = calculate(\n",
    "#             inet,\n",
    "#             to_select_per_sample = inet.node_count // 10,\n",
    "#             calibration_prior_estimates = {\n",
    "#                 \"PRECURSOR_RT\": 1,\n",
    "#                 \"PRECURSOR_MZ\": opt,\n",
    "#             },\n",
    "#         )\n",
    "#         ax[i].plot(*result_coordinates[\"PRECURSOR_MZ\"])\n",
    "#         # plt.axhline(y[-1])\n",
    "#     ax[i].legend(options)\n",
    "#     ax[i].set_title(inet.run_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "for selection in calibration_diffs:\n",
    "    a, b = np.unique(\n",
    "        np.round(calibration_diffs[selection][\"PRECURSOR_RT\"], 2),\n",
    "        return_counts=True\n",
    "    )\n",
    "    if selection == \"decoy\":\n",
    "        plt.plot(\n",
    "            a,\n",
    "            b * random_diffs[\"target\"][\"PRECURSOR_RT\"] / random_diffs[\"decoy\"][\"PRECURSOR_RT\"]\n",
    "        )\n",
    "    else:\n",
    "        plt.plot(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.concatenate(\n",
    "    [\n",
    "        calibration_diffs[\"target\"][\"PRECURSOR_RT\"],\n",
    "        calibration_diffs[\"decoy\"][\"PRECURSOR_RT\"],\n",
    "    ]\n",
    ")\n",
    "y = np.repeat(\n",
    "    [\n",
    "        1,\n",
    "        -random_diffs[\"target\"][\"PRECURSOR_RT\"] / random_diffs[\"decoy\"][\"PRECURSOR_RT\"]\n",
    "    ],\n",
    "    [\n",
    "        calibration_diffs[\"target\"][\"PRECURSOR_RT\"].shape[0],\n",
    "        calibration_diffs[\"decoy\"][\"PRECURSOR_RT\"].shape[0]\n",
    "    ]\n",
    ")\n",
    "o = np.argsort(x)\n",
    "x = x[o]\n",
    "y = np.cumsum(y[o])\n",
    "\n",
    "np.cumsum(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.axhline(y[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.axhline(y[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "x = np.linspace(-10,10,20000)\n",
    "y = np.empty(x.shape[0])\n",
    "\n",
    "for rt_diffs in rt_diff_list:\n",
    "    a, b = np.unique(\n",
    "        np.round(rt_diffs, 3),\n",
    "    #     np.round(mz_diffs/np.maximum(pmzs[indices1], pmzs[indices2])*1000000, -4),\n",
    "#         np.round(mz_diffs, 1),\n",
    "        return_counts=True\n",
    "    )\n",
    "    y[((a+10)*1000).astype(int)] += b\n",
    "#     plt.plot(a, b)\n",
    "#     plt.plot((np.sort(rt_diffs)), np.arange(len(rt_diffs))/(len(rt_diffs) - 1))\n",
    "\n",
    "plt.plot(x[y>10], y[y>10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "inet = inet1\n",
    "fints = fint1\n",
    "fmzs = fmz1\n",
    "pmzs = pmz1\n",
    "prts = prt1\n",
    "# isotopic_distance = 1.002861\n",
    "isotopic_distance = 113.084064\n",
    "# isotopic_distance = 130.058578\n",
    "ppm = 10\n",
    "to_select_per_sample = inet.node_count // 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = np.argpartition(fints, - to_select_per_sample)[-to_select_per_sample:]\n",
    "c = c[np.argsort(fmzs[c])]\n",
    "mzs = fmzs[c]\n",
    "if isotopic_distance > 0:\n",
    "    lower_limits = np.searchsorted(\n",
    "        mzs,\n",
    "        (mzs + isotopic_distance) / (1 + ppm * 10**-6),\n",
    "        \"left\"\n",
    "    )\n",
    "else:\n",
    "    lower_limits = np.arange(len(mzs)) + 1\n",
    "upper_limits = np.searchsorted(\n",
    "    mzs,\n",
    "    (mzs + isotopic_distance) * (1 + ppm * 10**-6),\n",
    "    \"right\"\n",
    ")\n",
    "indptr = np.zeros(inet.node_count + 1, np.int64)\n",
    "indptr[c + 1] = upper_limits - lower_limits\n",
    "indptr = np.cumsum(indptr)\n",
    "order = np.argsort(c)\n",
    "indices = np.concatenate(\n",
    "    [\n",
    "        c[low: high] for low, high in zip(lower_limits[order], upper_limits[order])\n",
    "    ]\n",
    ")\n",
    "len(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices1 = np.repeat(np.arange(inet.node_count), np.diff(indptr))\n",
    "indices2 = indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "mz_diffs = pmzs[indices1] - pmzs[indices2]\n",
    "rt_diffs = prts[indices1] - prts[indices2]\n",
    "\n",
    "# sns.jointplot(mz_diffs, rt_diffs)\n",
    "\n",
    "# sns.jointplot(mz_diffs, rt_diffs, kind=\"hex\", gridsize=100)\n",
    "\n",
    "a, b = np.unique(\n",
    "    np.round(rt_diffs, 2),\n",
    "#     np.round(mz_diffs/np.maximum(pmzs[indices1], pmzs[indices2])*1000000, -4),\n",
    "#     np.round(mz_diffs, 1),\n",
    "    return_counts=True\n",
    ")\n",
    "plt.plot(a, b)\n",
    "\n",
    "# plt.plot(np.arange(len(rt_diffs))/(len(rt_diffs) - 1), (np.sort(rt_diffs)))\n",
    "# plt.plot((np.sort(rt_diffs)), np.arange(len(rt_diffs))/(len(rt_diffs) - 1))\n",
    "# plt.plot(np.arange(len(rt_diffs_rnd))/(len(rt_diffs_rnd) - 1), (np.sort(np.abs(rt_diffs_rnd))))\n",
    "\n",
    "# plt.plot((np.sort(mz_diffs)), np.arange(len(mz_diffs))/(len(mz_diffs) - 1))\n",
    "# plt.plot((np.sort(mz_diffs_rnd)), np.arange(len(mz_diffs_rnd))/(len(mz_diffs_rnd) - 1))\n",
    "\n",
    "# plt.plot((np.sort(rt_diffs)), np.arange(len(rt_diffs))/(len(rt_diffs) - 1))\n",
    "# plt.plot((np.sort(rt_diffs_rnd)), np.arange(len(rt_diffs_rnd))/(len(rt_diffs_rnd) - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_diffs_sorted = np.sort(rt_diffs)\n",
    "rt_diffs_rnd_sorted = np.sort(rt_diffs_rnd)\n",
    "rtd_l, rtd_h = np.searchsorted(rt_diffs_sorted, [-1, 1])\n",
    "rtd_rnd_l, rtd_rnd_h = np.searchsorted(rt_diffs_rnd_sorted, [-1, 1])\n",
    "rtd_bg = len(rt_diffs_sorted) - (rtd_h-rtd_l)\n",
    "rtd_rnd_bg = len(rt_diffs_rnd_sorted) - (rtd_rnd_h-rtd_rnd_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "# sns.jointplot(mz_diffs, rt_diffs)\n",
    "\n",
    "# sns.jointplot(mz_diffs, rt_diffs, kind=\"hex\", gridsize=400)\n",
    "\n",
    "a, b = np.unique(\n",
    "    np.round(rt_diffs, 2),\n",
    "#     np.round(mz_diffs/np.maximum(pmzs[indices1], pmzs[indices2])*1000000, -4),\n",
    "#     np.round(mz_diffs, 1),\n",
    "    return_counts=True\n",
    ")\n",
    "plt.plot(a, b)\n",
    "a, b = np.unique(\n",
    "    np.round(rt_diffs_rnd, 2),\n",
    "#     np.round(mz_diffs/np.maximum(pmzs[indices1], pmzs[indices2])*1000000, -4),\n",
    "#     np.round(mz_diffs, 1),\n",
    "    return_counts=True\n",
    ")\n",
    "plt.plot(a, b * rtd_bg / rtd_rnd_bg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "resolution = 1500\n",
    "\n",
    "x = np.linspace(-10, 10, resolution)\n",
    "y = np.zeros(resolution)\n",
    "\n",
    "a, b = np.unique(\n",
    "    np.round(rt_diffs, 2),\n",
    "#     np.round(mz_diffs/np.maximum(pmzs[indices1], pmzs[indices2])*1000000, -4),\n",
    "#     np.round(mz_diffs, 1),\n",
    "    return_counts=True\n",
    ")\n",
    "y[(((a+10)/20)*(resolution-1)).astype(int)] += b\n",
    "\n",
    "a, b = np.unique(\n",
    "    np.round(rt_diffs_rnd, 2),\n",
    "#     np.round(mz_diffs/np.maximum(pmzs[indices1], pmzs[indices2])*1000000, -4),\n",
    "#     np.round(mz_diffs, 1),\n",
    "    return_counts=True\n",
    ")\n",
    "y[(((a+10)/20)*(resolution-1)).astype(int)] -= b * rtd_bg / rtd_rnd_bg\n",
    "\n",
    "plt.plot(x,y)\n",
    "# plt.plot(x[y>0],y[y>0])\n",
    "# from scipy.signal import argrelextrema\n",
    "# argrelextrema(y, np.less)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.signal.peak_widths(y, [resolution//2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "# z=np.bincount(((rt_diffs+10)*100).astype(int))\n",
    "# zz=scipy.signal.find_peaks_cwt(z,  np.arange(1,10))\n",
    "# plt.plot(np.linspace(-10,10,z.shape[0]), z)\n",
    "# plt.scatter(np.linspace(-10,10,z.shape[0])[zz], z[zz], c=\"r\")\n",
    "zz=scipy.signal.find_peaks_cwt(y,  np.arange(1,10))\n",
    "plt.plot(x,y)\n",
    "plt.scatter(x[zz], y[zz], c=\"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "outliers = is_outlier(mz_diffs, thresh=.01)\n",
    "\n",
    "a, b = np.unique(\n",
    "#     np.round(rt_diffs, 2),\n",
    "    np.round(mz_diffs[outliers], 1),\n",
    "    return_counts=True\n",
    ")\n",
    "plt.plot(a, b)\n",
    "\n",
    "a, b = np.unique(\n",
    "#     np.round(rt_diffs, 2),\n",
    "    np.round(mz_diffs[~outliers], 1),\n",
    "    return_counts=True\n",
    ")\n",
    "plt.plot(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.sort(np.abs(rt_diffs))\n",
    "b = np.sort(np.abs(rt_diffs_rnd))\n",
    "c = np.searchsorted(a,b, \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = np.arange(len(b))/len(b)\n",
    "j = c/len(a)\n",
    "l = ((1-i)+(j))\n",
    "plt.plot(b, l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sklearn.cluster\n",
    "# clusterer = sklearn.cluster.DBSCAN(eps=10, min_samples=3).fit(\n",
    "#     np.stack([mz_diffs, rt_diffs]).T\n",
    "# )\n",
    "\n",
    "g = np.abs(mz_diffs) < 10\n",
    "g &= np.abs(rt_diffs) < 0.2\n",
    "\n",
    "import hdbscan\n",
    "clusterer = hdbscan.HDBSCAN().fit(\n",
    "    np.stack(\n",
    "        [\n",
    "            mz_diffs[g],\n",
    "            rt_diffs[g]\n",
    "        ]\n",
    "    ).T\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "plt.scatter(\n",
    "    mz_diffs[g],\n",
    "    rt_diffs[g],\n",
    "    c=clusterer.labels_,\n",
    "#     cmap=\\\"gist_ncar\\\"\n",
    "    cmap=\"tab20\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.njit(cache=True, nogil=True)\n",
    "def increase_buffer(buffer, max_batch=10**7):\n",
    "    new_buffer = np.empty(buffer.shape[0] + max_batch, np.int64)\n",
    "    new_buffer[:len(buffer)] = buffer\n",
    "    return new_buffer\n",
    "\n",
    "@numba.njit(cache=True, nogil=True)\n",
    "def __determine_precursor_edges(\n",
    "    queries,\n",
    "    lower_limits,\n",
    "    upper_limits,\n",
    "    coordinates,\n",
    "    max_errors,\n",
    "):\n",
    "    indptr = np.zeros(len(queries), np.int64)\n",
    "    indices = np.empty(10**7, np.int64)\n",
    "    total = 0\n",
    "    for index, query in enumerate(queries):\n",
    "        low_limit = lower_limits[query]\n",
    "        high_limit = upper_limits[query]\n",
    "        candidate_count = high_limit - low_limit\n",
    "        if candidate_count == 0:\n",
    "            continue\n",
    "        elif (candidate_count + total) >= len(indices):\n",
    "            indices = increase_buffer(indices)\n",
    "        dists = coordinates[low_limit: high_limit] - coordinates[query]\n",
    "        dists /= max_errors\n",
    "#         TODO: what if error==0?\n",
    "        dists = dists**2\n",
    "        projected_dists = np.sum(dists, axis=1)\n",
    "        projected_dists = np.sqrt(projected_dists)\n",
    "        candidates = low_limit + np.flatnonzero(projected_dists <= 1)\n",
    "        candidate_count = len(candidates)\n",
    "        indices[total: total + candidate_count] = candidates\n",
    "        indptr[index] = candidate_count\n",
    "        total += candidate_count\n",
    "    return (indptr, indices[:total])\n",
    "\n",
    "def determine_precursor_edges(\n",
    "    self,\n",
    "    errors,\n",
    "    thread_count=1,\n",
    "):\n",
    "    precursor_coordinates = np.stack(\n",
    "        self.get_ion_coordinates(self.precursor_dimensions)\n",
    "    ).T\n",
    "    max_errors = np.array(\n",
    "        [errors[dimension] for dimension in self.precursor_dimensions]\n",
    "    )\n",
    "    rt_coordinates = self.get_ion_coordinates(\"PRECURSOR_RT\")\n",
    "    lower_limits = np.arange(len(rt_coordinates)) + 1\n",
    "    upper_limits = np.searchsorted(\n",
    "        rt_coordinates,\n",
    "        rt_coordinates + errors[\"PRECURSOR_RT\"],\n",
    "        \"right\"\n",
    "    )\n",
    "    with multiprocessing.pool.ThreadPool(thread_count) as p:\n",
    "        results = p.starmap(\n",
    "            __determine_precursor_edges,\n",
    "            [\n",
    "                (\n",
    "                    np.arange(\n",
    "                        (i * self.node_count) // thread_count,\n",
    "                        ((i + 1) * self.node_count) // thread_count\n",
    "                    ),\n",
    "                    lower_limits,\n",
    "                    upper_limits,\n",
    "                    precursor_coordinates,\n",
    "                    max_errors\n",
    "                ) for i in range(thread_count)\n",
    "            ]\n",
    "        )\n",
    "    indptr = np.empty(self.node_count + 1, np.int64)\n",
    "    indptr[0] = 0\n",
    "    indptr[1:] = np.cumsum(np.concatenate([r[0] for r in results]))\n",
    "    indices = np.concatenate([r[1] for r in results])\n",
    "#     self.write_group(\"edges\")\n",
    "#     self.write_dataset(\n",
    "#         \"indptr\",\n",
    "#         indptr,\n",
    "#         parent_group_name=\"edges\"\n",
    "#     )\n",
    "#     self.write_dataset(\n",
    "#         \"indices\",\n",
    "#         indices,\n",
    "#         parent_group_name=\"edges\"\n",
    "#     )\n",
    "#     self.write_attr(\"edge_count\", len(indices))\n",
    "#     for parameter_key, parameter_value in parameters.items():\n",
    "#         if parameter_key.startswith(\"max_edge_absolute_error\"):\n",
    "#             if parameter_key[19:] in self.dimensions:\n",
    "#                 self.write_attr(parameter_key, parameter_value)\n",
    "    return indptr, indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = determine_precursor_edges(\n",
    "    inet,\n",
    "    {\n",
    "        \"PRECURSOR_RT\": 0.1,\n",
    "        \"PRECURSOR_MZ\": 0,\n",
    "    },\n",
    "    thread_count=8,\n",
    ")\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeit(\n",
    "    lambda: determine_precursor_edges(\n",
    "        inet,\n",
    "        max_errors=np.array((5, 0.1)),\n",
    "        max_rt_absolute_error=0.1,\n",
    "        thread_count=8,\n",
    "    ),\n",
    "    number=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = r[1]\n",
    "# a = np.repeat(np.arange(len(r[0]) - 1), np.diff(r[0]))\n",
    "a = r[0]\n",
    "print(len(a), len(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmzs, prts = inet.get_ion_coordinates(inet.precursor_dimensions)\n",
    "fints, fmzs = inet.get_ion_coordinates([\"FRAGMENT_LOGINT\", \"FRAGMENT_MZ\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_select_per_sample = 100000\n",
    "c = np.argpartition(fints, - to_select_per_sample)[-to_select_per_sample:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.repeat(np.arange(len(a) - 1), np.diff(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.isin(a,c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "mzds = np.repeat(pmzs, np.diff(a)) - pmzs[b]\n",
    "rtds = np.repeat(prts, np.diff(a)) - prts[b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook \n",
    "plt.scatter(pmzs[c], prts[c])\n",
    "# a,b = np.unique(\n",
    "#     np.round(\n",
    "#         prts[c],\n",
    "#         3\n",
    "#     ),\n",
    "#     return_counts=True\n",
    "# )\n",
    "# plt.plot(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload()\n",
    "\n",
    "inets = []\n",
    "evis = []\n",
    "anis = []\n",
    "# in_folder = \"/home/sander/Documents/Proteomics/data/ion_networks\"\n",
    "in_folder = \"/home/sander/Documents/Proteomics/data/ecoli3\"\n",
    "# in_folder = \"/home/sander/Documents/Proteomics/data/jpt/APEX\"\n",
    "for file_name in ms_utils.get_file_names_with_extension([in_folder], \".inet.hdf\"):\n",
    "    inets.append(\n",
    "        ms_run_files.Network(\n",
    "            file_name\n",
    "        )\n",
    "    )\n",
    "    evis.append(\n",
    "        ms_run_files.Evidence(\n",
    "            file_name\n",
    "        )\n",
    "    )\n",
    "    anis.append(\n",
    "        ms_run_files.Annotation(\n",
    "            file_name\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ani_indices = anis[0].get_dataset(\"indices\", 'edge_candidates')\n",
    "ani_indptr = anis[0].get_dataset(\"indptr\", 'edge_candidates')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anis[0].get_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "from numba import njit, jit, guvectorize\n",
    "import timeit\n",
    "import numpy as np\n",
    "\n",
    "@njit\n",
    "def square_sum(arr):\n",
    "    a = 0.\n",
    "    for i in range(arr.size):\n",
    "        a = np.sqrt(a**2 + arr[i]**2)  # sqrt and square are cpu-intensive!\n",
    "    return a\n",
    "\n",
    "@njit\n",
    "def is_close(x, y, max_errors):\n",
    "    z = x - y\n",
    "    z /= max_errors\n",
    "    z = np.sqrt(np.sum(z**2))\n",
    "    return z < 1\n",
    "\n",
    "@guvectorize([\"void(float64[:], float64[:], float64[:], bool_[:])\"], \"(n), (n), (n) -> ()\", target=\"parallel\", nopython=True)\n",
    "def row_sum_gu(input, coordinate, max_errors, output) :\n",
    "    output[0] = is_close(input, coordinate, max_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = int(64)\n",
    "columns = int(1e6)\n",
    "\n",
    "input_array = np.random.random((rows, columns))\n",
    "output_array = np.zeros((rows))\n",
    "# row_sum_jit(input_array, output_array.copy())\n",
    "t1 = timeit.timeit(\n",
    "    lambda:row_sum_jit(input_array, output_array.copy()),\n",
    "#     lambda: np.sum(rows),\n",
    "    number=1\n",
    ")\n",
    "t2 = timeit.timeit(\n",
    "    lambda:row_sum_gu(input_array, output_array.copy()),\n",
    "#     lambda: np.sum(rows),\n",
    "    number=1\n",
    ")\n",
    "print(t1,t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.flatnonzero(row_sum_gu(x,y,m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload()\n",
    "\n",
    "ion_network_file_name = \"/home/sander/Documents/Proteomics/data/ecoli2/28Oct2016_064.inet.hdf\"\n",
    "csv_file_name = \"/home/sander/Documents/Proteomics/data/ecoli/28Oct2016_064.inet.csv\"\n",
    "\n",
    "ms_run_files.Network.write_edges = profile(ms_run_files.Network.write_edges)\n",
    "\n",
    "parameters = ms_utils.read_parameters_from_json_file(\n",
    "#     file_name=parameter_file_name,\n",
    "    default=\"create\"\n",
    ")\n",
    "network = ms_run_files.Network(\n",
    "    ion_network_file_name,\n",
    "    new_file=True,\n",
    ")\n",
    "data = ms_utils.read_centroided_csv_file(\n",
    "    csv_file_name,\n",
    "    parameters,\n",
    ")\n",
    "network.create_from_data(data, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self_inet = inets[0]\n",
    "self_evi = evis[0]\n",
    "other_inet = inets[1]\n",
    "other_evi = evis[1]\n",
    "\n",
    "self_alignment = self_evi.get_aligned_nodes_from_group(\n",
    "    other_evi.file_name_base,\n",
    "    return_as_mask=False\n",
    ")\n",
    "other_alignment = other_evi.get_aligned_nodes_from_group(\n",
    "    self_evi.file_name_base,\n",
    "    return_as_mask=False\n",
    ")\n",
    "# other_logints = inets[other_name].get_ion_coordinates(\n",
    "#     \"FRAGMENT_LOGINT\",\n",
    "#     indices=other_alignment\n",
    "# )\n",
    "# logints[i, self_alignment] = other_logints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "ind_start = 0\n",
    "ind_size = len(self_alignment)\n",
    "\n",
    "a1 = self_inet.get_ion_coordinates(\"PRECURSOR_RT\", indices = self_alignment[ind_start: ind_start+ind_size])\n",
    "b1 = self_inet.get_ion_coordinates(\"PRECURSOR_MZ\", indices = self_alignment[ind_start: ind_start+ind_size])\n",
    "a2 = other_inet.get_ion_coordinates(\"PRECURSOR_RT\", indices = other_alignment[ind_start: ind_start+ind_size])\n",
    "b2 = other_inet.get_ion_coordinates(\"PRECURSOR_MZ\", indices = other_alignment[ind_start: ind_start+ind_size])\n",
    "\n",
    "# ax=\n",
    "\n",
    "start_edges = list(zip(a1, b1))\n",
    "end_edges = list(zip(a2, b2))\n",
    "# colors = positive_counts[selection] - negative_counts[selection]\n",
    "edges = np.array(list(zip(start_edges, end_edges)))\n",
    "\n",
    "x = ax.add_collection(\n",
    "    matplotlib.collections.LineCollection(edges),\n",
    ")\n",
    "x.set_color(\"grey\")\n",
    "ax.scatter(a1, b1, marker=\".\", c=\"g\", zorder=10)\n",
    "ax.scatter(a2, b2, marker=\".\", c=\"r\", zorder=10)\n",
    "ax.set_xlabel(\"PRECURSOR_RT\")\n",
    "ax.set_ylabel(\"PRECURSOR_MZ\")\n",
    "# sns.jointplot(a1[ind_start: ind_start+ind_size], a2[ind_start: ind_start+ind_size], kind=\"kde\",gridsize=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "sorted(matplotlib.colors.__dict__['CSS4_COLORS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repro = evi.get_aligned_nodes_from_group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inet=inets[0]\n",
    "evi=evis[0]\n",
    "\n",
    "%matplotlib notebook\n",
    "coords = inet.get_ion_coordinates(inet2.dimensions)\n",
    "print(inet.dimensions)\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# repro = evi.get_aligned_nodes_from_group()\n",
    "\n",
    "selection = (coords[3] > 30) & (coords[3] < 30.2)\n",
    "selection &= (coords[2] < 2000)\n",
    "selection &= (coords[1] < 900)\n",
    "# selection=...\n",
    "\n",
    "# sns.jointplot(coords[1][selection], coords[2][selection], kind=\"hex\", gridsize=200)\n",
    "ax.scatter(\n",
    "    coords[1][selection],\n",
    "    coords[3][selection],\n",
    "    coords[2][selection],\n",
    "    marker=\".\",\n",
    "    c=coords[0][selection],\n",
    "    cmap=\"RdYlGn\"\n",
    ")\n",
    "ax.set_xlabel(inet.dimensions[1])\n",
    "ax.set_ylabel(inet.dimensions[3])\n",
    "ax.set_zlabel(inet.dimensions[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload()\n",
    "\n",
    "an = annotation.Annotation(\n",
    "    evidence=evis[0],\n",
    "    database=\"/home/sander/Documents/Proteomics/data/databases/hdf/crap_ecoli_concatenated_decoy.hdf\",\n",
    "    parameters={\n",
    "        \"annotation_ppm\": 20,\n",
    "    },\n",
    "    logger=logger\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self=inets[1]\n",
    "# indptr, indices = self.get_edges(\n",
    "#     indptr_and_indices=True\n",
    "# )\n",
    "# x, y = self.get_edges(return_as_scipy_csr=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rts = self.get_ion_coordinates(\"PRECURSOR_RT\")\n",
    "rts[:1000000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload()\n",
    "\n",
    "self = inets[0]\n",
    "other = inets[1]\n",
    "# self_ints, self_mzs, self_pmzs, self_rts = self.get_ion_coordinates()\n",
    "# other_ints, other_mzs, other_pmzs, other_rts = other.get_ion_coordinates()\n",
    "# calibrated_self_rts = sandbox.calibrate_precursor_rt(self, other, ppm=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self_mzs = pd.read_csv(\n",
    "    \"/home/sander/Documents/Proteomics/data/jpt/APEX/200117_JPTmix_prop_Fullloop_01_Apex3DIons.inet.csv\",\n",
    "    usecols=[\"FRAGMENT_MZ\"]\n",
    ").values.flatten()\n",
    "other_mzs = pd.read_csv(\n",
    "    \"/home/sander/Documents/Proteomics/data/jpt/APEX/200117_JPTmix_prop_Fullloop_08_Apex3DIons.inet.csv\",\n",
    "    usecols=[\"FRAGMENT_MZ\"]\n",
    ").values.flatten()\n",
    "\n",
    "self_logints = pd.read_csv(\n",
    "    \"/home/sander/Documents/Proteomics/data/jpt/APEX/200117_JPTmix_prop_Fullloop_01_Apex3DIons.inet.csv\",\n",
    "    usecols=[\"FRAGMENT_LOGINT\"]\n",
    ").values.flatten()\n",
    "other_logints = pd.read_csv(\n",
    "    \"/home/sander/Documents/Proteomics/data/jpt/APEX/200117_JPTmix_prop_Fullloop_08_Apex3DIons.inet.csv\",\n",
    "    usecols=[\"FRAGMENT_LOGINT\"]\n",
    ").values.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# le_indices = np.concatenate(\n",
    "#     [\n",
    "#         start + np.argpartition(\n",
    "#             ions[\"INTENSITY\"][start: end], - to_select_per_sample\n",
    "#         )[-to_select_per_sample:] for start, end in zip(\n",
    "#             start_indices[:-1],\n",
    "#             start_indices[1:]\n",
    "#         )\n",
    "#     ]\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration_ions = 50000\n",
    "self_ions = np.argpartition(self_logints, -calibration_ions)[-calibration_ions:]\n",
    "other_ions = np.argpartition(other_logints, -calibration_ions)[-calibration_ions:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self_mzs = self_mzs[self_ions]\n",
    "other_mzs = other_mzs[other_ions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(self_mzs), np.sort(other_mzs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self_mzs = self.get_ion_coordinates(\"FRAGMENT_MZ\")\n",
    "other_mzs = other.get_ion_coordinates(\"FRAGMENT_MZ\")\n",
    "# self_indices, other_indices = sandbox.quick_align(self_mzs, other_mzs, ppm=10)\n",
    "# self_rts = self.get_ion_coordinates(\"PRECURSOR_RT\")\n",
    "# other_rts = other.get_ion_coordinates(\"PRECURSOR_RT\", indices=other_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self_inds = np.repeat(0, len(self_mzs))\n",
    "other_inds = np.repeat(1, len(other_mzs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mzs = np.concatenate([self_mzs, other_mzs])\n",
    "inds = np.concatenate([self_inds, other_inds])\n",
    "order = np.argsort(mzs)\n",
    "mzs = mzs[order]\n",
    "inds = inds[order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mz_diffs = np.diff(mzs)\n",
    "ind_diffs = np.diff(inds)\n",
    "x = np.concatenate([mz_diffs[ind_diffs==1], -mz_diffs[ind_diffs==-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = (mz_diffs[:-2] < mz_diffs[1:-1]) & (mz_diffs[1:-1] < mz_diffs[2:])\n",
    "x &= ind_diffs[1:-1] != 0\n",
    "x = mz_diffs[1:-1][x] * -ind_diffs[1:-1][x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.quantile(\n",
    "    mz_diffs[ind_diffs==-1] * 10**6 / mzs[:-1][ind_diffs==-1],\n",
    "    0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "# s = np.concatenate([mz_diffs[ind_diffs==1], -mz_diffs[ind_diffs==-1]])\n",
    "\n",
    "plt.scatter(\n",
    "    mzs[:-1][ind_diffs==1],\n",
    "    mz_diffs[ind_diffs==1] * 10**6 / mzs[:-1][ind_diffs==1]\n",
    "#     np.sort(self_mzs),\n",
    "#     np.sort(other_mzs) - np.sort(self_mzs),\n",
    "#     10**6 * (np.sort(self_mzs) - np.sort(other_mzs)) / np.sort(self_mzs)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "a, b = np.unique(np.round(x,3), return_counts=True)\n",
    "print(np.quantile(x, np.arange(101)/100), np.median(x))\n",
    "# plt.plot(a,b)\n",
    "plt.plot(np.quantile(x, np.arange(101)/100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_self_rts = []\n",
    "for self_start_index, self_end_index, other_rt_start, other_rt_end in zip(\n",
    "    self_indices[:-1],\n",
    "    self_indices[1:],\n",
    "    other_rts[:-1],\n",
    "    other_rts[1:]\n",
    "):\n",
    "#     if self_end_index == self_start_index:\n",
    "#         continue\n",
    "    self_rt_start = self_rts[self_start_index]\n",
    "    self_rt_end = self_rts[self_end_index]\n",
    "    if self_rt_start == self_rt_end:\n",
    "        new_rts = np.repeat(other_rt_start, self_end_index - self_start_index)\n",
    "    else:\n",
    "        slope = (other_rt_end - other_rt_start) / (self_rt_end - self_rt_start)\n",
    "        new_rts = other_rt_start + slope * (\n",
    "            self_rts[self_start_index: self_end_index] - self_rt_start\n",
    "        )\n",
    "    new_self_rts.append(new_rts)\n",
    "new_self_rts.append([other_rts[-1]])\n",
    "new_self_rts = np.concatenate(new_self_rts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_self_rts.shape[0] - self_rts.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self_rts = self.get_ion_coordinates(\"PRECURSOR_RT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "plt.scatter(self_rts, self_rts - calibrated_self_rts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload()\n",
    "\n",
    "self_ints, self_mzs, self_dts, self_rts = self.get_ion_coordinates()\n",
    "other_ints, other_mzs, other_dts, other_rts = other.get_ion_coordinates()\n",
    "self_indices, other_indices = sandbox.quick_align(self_mzs, other_mzs, ppm=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s = slice(0, None, 1000)\n",
    "a1 = self_rts[self_indices]\n",
    "a2 = other_rts[other_indices]\n",
    "c = self_dts[self_indices] - other_dts[other_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppm=10\n",
    "\n",
    "self_mz_order = np.argsort(self_mzs)\n",
    "other_mz_order = np.argsort(other_mzs)\n",
    "max_mz_diff = 1 + ppm * 10**-6\n",
    "low_limits = np.searchsorted(\n",
    "    self_mzs[self_mz_order],\n",
    "    other_mzs[other_mz_order] / max_mz_diff,\n",
    "    \"left\"\n",
    ")\n",
    "high_limits = np.searchsorted(\n",
    "    self_mzs[self_mz_order],\n",
    "    other_mzs[other_mz_order] * max_mz_diff,\n",
    "    \"right\"\n",
    ")\n",
    "other_rt_order = np.argsort(other_mz_order)\n",
    "self_indices = np.concatenate(\n",
    "    [\n",
    "        self_mz_order[l:h] for l, h in zip(\n",
    "            low_limits[other_rt_order],\n",
    "            high_limits[other_rt_order]\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "other_indices = np.repeat(\n",
    "    np.arange(len(other_rt_order)),\n",
    "    high_limits[other_rt_order] - low_limits[other_rt_order]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "plt.plot(a1, a2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "# plt.plot(a1, a2)\n",
    "# plt.scatter(a1, a2, marker=\".\", c=c, cmap=\"RdYlGn\")\n",
    "# sns.jointplot(a1, a2, kind=\"hex\", gridsize=200)\n",
    "# sns.jointplot(self_rts[self_indices], other_rts[other_indices], kind=\"hex\", gridsize=100)\n",
    "plt.scatter(self_rts[self_indices], other_rts[other_indices], marker=\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "a,b=np.unique(np.round(c,0), return_counts=True)\n",
    "plt.plot(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self_rts = self.get_ion_coordinates(\"PRECURSOR_RT\")\n",
    "other_rts = other.get_ion_coordinates(\"PRECURSOR_RT\", indices=other_indices)\n",
    "new_self_rts = []\n",
    "for self_start_index, self_end_index, other_rt_start, other_rt_end in zip(\n",
    "    self_indices[:-1],\n",
    "    self_indices[1:],\n",
    "    other_rts[:-1],\n",
    "    other_rts[1:]\n",
    "):\n",
    "    self_rt_start = self_rts[self_start_index]\n",
    "    self_rt_end = self_rts[self_end_index]\n",
    "    if self_rt_start == self_rt_end:\n",
    "        new_rts = np.repeat(other_rt_start, self_end_index - self_start_index)\n",
    "    else:\n",
    "        slope = (other_rt_end - other_rt_start) / (self_rt_end - self_rt_start)\n",
    "        new_rts = other_rt_start + slope * (\n",
    "            self_rts[self_start_index: self_end_index] - self_rt_start\n",
    "        )\n",
    "    new_self_rts.append(new_rts)\n",
    "new_self_rts.append([other_rts[-1]])\n",
    "new_self_rts = np.concatenate(new_self_rts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib notebook\n",
    "\n",
    "# s = slice(0, None, 1000)\n",
    "# plt.scatter(new_self_rts[s], self_rts[s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ints, mzs, pmzs, rts = inets[0].get_ion_coordinates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload()\n",
    "\n",
    "ali = evis[0].get_alignment(evis[1])\n",
    "# pairwise_alignment = inets[0].align_nodes(\n",
    "#     inets[1],\n",
    "#     parameters\n",
    "# )\n",
    "# ali = [\n",
    "#     pairwise_alignment.T.tocsr().indices,\n",
    "#     pairwise_alignment.indices\n",
    "# ]\n",
    "# a = np.repeat(np.arange(pairwise_alignment.shape[0]), np.diff(pairwise_alignment.indptr))\n",
    "# aa = pairwise_alignment.nonzero()[0]\n",
    "# a,aa,np.bincount(a==aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rt_diffs(isotopic_distance, ppm, rts):\n",
    "    mz_order = np.argsort(mzs)\n",
    "    mzs_in_mz_order = mzs[mz_order]\n",
    "    if isotopic_distance > 0:\n",
    "        lower_limits = np.searchsorted(\n",
    "            mzs_in_mz_order,\n",
    "            (mzs_in_mz_order + isotopic_distance) / (1 + ppm * 10**-6),\n",
    "            \"left\"\n",
    "        )\n",
    "    else:\n",
    "        lower_limits = np.arange(len(mzs)) + 1\n",
    "    upper_limits = np.searchsorted(\n",
    "        mzs_in_mz_order,\n",
    "        (mzs_in_mz_order + isotopic_distance) * (1 + ppm * 10**-6),\n",
    "        \"right\"\n",
    "    )\n",
    "    first_isotopic_pairs = np.repeat(mz_order, upper_limits - lower_limits)\n",
    "    second_isotopic_pairs = np.concatenate([mz_order[l: u] for u, l in zip(upper_limits, lower_limits)])\n",
    "    return np.abs(rts[first_isotopic_pairs] - rts[second_isotopic_pairs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isotopic_rts = rt_diffs(isotopic_distance = 1.002, ppm=2, rts=rts)\n",
    "random_rts = rt_diffs(isotopic_distance = 3.8254, ppm=2, rts=rts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_rts = np.concatenate([isotopic_rts, random_rts])\n",
    "all_labels = np.repeat([False, True], [len(isotopic_rts), len(random_rts)])\n",
    "order = np.argsort(all_rts)\n",
    "all_rts = all_rts[order]\n",
    "all_labels = all_labels[order]\n",
    "fdr = np.cumsum(all_labels) / (1 + np.arange(len(all_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmin(fdr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "s = slice(0,10000000, 1)\n",
    "plt.plot(all_rts[s], fdr[s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isotope_rt_diffs, isotope_count = np.unique(\n",
    "        isotopic_rts,\n",
    "        return_counts=True\n",
    "    )\n",
    "isotope_count = np.cumsum(isotope_count)\n",
    "random_rt_diffs, random_count = np.unique(\n",
    "        random_rts,\n",
    "        return_counts=True\n",
    "    )\n",
    "random_count = np.cumsum(random_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_diffs = isotope_rt_diffs\n",
    "# random_counts = isotope_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "# plt.plot(\n",
    "#     *np.unique(\n",
    "#         np.round(\n",
    "#             rts[first_isotopic_pairs] - rts[second_isotopic_pairs],\n",
    "#             3\n",
    "#         ),\n",
    "#         return_counts=True\n",
    "#     )\n",
    "# )\n",
    "\n",
    "\n",
    "plt.plot(\n",
    "    isotope_rt_diffs, isotope_count/isotope_count[-1]\n",
    ")\n",
    "plt.plot(\n",
    "    random_rt_diffs, random_count/random_count[-1]\n",
    ")\n",
    "# plt.plot(\n",
    "#     random_diffs, random_counts/random_counts[-1]+0.0029-0.001, c=\"r\"\n",
    "# )\n",
    "# plt.plot(\n",
    "#     random_diffs, random_counts/random_counts[-1]+0.0029+0.0015, c=\"r\"\n",
    "# )\n",
    "# plt.plot(\n",
    "#     random_diffs, random_counts/random_counts[-1], c=\"r\"\n",
    "# )\n",
    "plt.axhline(0.5, c=\"grey\")\n",
    "plt.axvline(0, c=\"grey\")\n",
    "# plt.plot([-15,15], [0.313,0.69])\n",
    "\n",
    "# plt.plot(\n",
    "#     isotope_rt_diffs,\n",
    "#     np.gradient(isotope_count),\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "ricos = np.diff(isotope_count) / np.diff(isotope_rt_diffs)\n",
    "plt.plot(isotope_rt_diffs[:-1], ricos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "sns.jointplot(\n",
    "    rts[first_isotopic_pairs[::10]],\n",
    "    rts[second_isotopic_pairs[::10]],\n",
    "    kind=\"hex\",\n",
    "    gridsize=500\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "sns.jointplot(\n",
    "    inets[0].get_ion_coordinates(\"FRAGMENT_LOGINT\", indices=ali[:,0]),\n",
    "    inets[1].get_ion_coordinates(\"FRAGMENT_LOGINT\", indices=ali[:,1]),\n",
    "    kind=\"hex\",\n",
    "    gridsize=500\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left, right = inets[0].get_edges(return_as_scipy_csr=False)\n",
    "mzs = inets[0].get_ion_coordinates(\"MZ2\")\n",
    "diffs2 = mzs[left] - mzs[right]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = evidences[0].get_evidence(network_keys=[k.key for k in inets[1:]], return_total=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = inets[0].get_edges()\n",
    "edges.data = z[0] > z[1] + 8\n",
    "edges.eliminate_zeros()\n",
    "left, right = edges.nonzero()\n",
    "mzs = inets[0].get_ion_coordinates(\"MZ2\")\n",
    "diffs = mzs[left] - mzs[right]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ori_a, ori_b = np.unique(np.round(diffs2, 3), return_counts=True)\n",
    "new_a, new_b = np.unique(np.round(diffs, 3), return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "plt.plot(ori_a, ori_b/np.max(ori_b))\n",
    "plt.plot(new_a, new_b/np.max(new_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mzs = inets[0].get_ion_coordinates(\"MZ2\")\n",
    "diffs = np.abs(mzs[left] - mzs[right])\n",
    "good = np.abs(diffs - 1.002) < 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inets[0].get_ion_coordinates(indices=z[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posi = z[0][good]\n",
    "negi = z[1][good]\n",
    "np.bincount(posi), np.bincount(negi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iso = np.histogram2d(posi, negi, bins=10)[0].astype(np.int)\n",
    "# total = np.histogram2d(z[0], z[1], bins=10)[0].astype(np.int)\n",
    "iso, total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "# sns.heatmap(np.log(iso/total), cmap=\"RdYlGn\")\n",
    "sns.heatmap(np.log(iso + 1), cmap=\"RdYlGn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = (z[0] + z[1]) > 0\n",
    "# np.unique(z[0][selected] / (z[0] + z[1])[selected], return_counts=True)\n",
    "a, b = np.unique(z[0][selected]-z[1][selected], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "plt.plot(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "first_mz2, first_rt1, first_mz1, first_logint = inets[0].get_ion_coordinates([\"MZ2\", \"RT\", \"MZ1\", \"LOGINT\"])\n",
    "second_mz2, second_rt2, second_mz1, second_logint = inets[1].get_ion_coordinates([\"MZ2\", \"RT\", \"MZ1\", \"LOGINT\"])\n",
    "a = al.get_alignment(inets[0], inets[1], return_as_scipy_csr=False)\n",
    "\n",
    "sns.jointplot(first_mz1, first_mz2, kind=\"hex\", gridsize=500)\n",
    "sns.jointplot(first_logint[a[:,0]], second_logint[a[:,1]], kind=\"hex\", gridsize=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(network)\n",
    "mzs, rts = inet.get_ion_coordinates([\"MZ2\", \"RT\"])\n",
    "isotopic_distance = 1.002\n",
    "ppm = 10\n",
    "\n",
    "isotope_rt_diffs, isotope_count = network.determine_isotopic_rt_difference(\n",
    "    mzs,\n",
    "    rts,\n",
    "    isotopic_distance,\n",
    "    ppm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mz_order = np.argsort(mzs)\n",
    "# mzs_in_mz_order = mzs[mz_order]\n",
    "# print(mzs_in_mz_order, (mzs_in_mz_order + isotopic_distance) * (1 + ppm * 10**-6))\n",
    "rts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratios = []\n",
    "resolution = np.linspace(0,1,100)\n",
    "lower_limits = np.arange(len(rts)) + 1\n",
    "for limit in resolution:\n",
    "    upper_limits = np.searchsorted(\n",
    "        rts,\n",
    "        rts + limit,\n",
    "        \"right\"\n",
    "    )\n",
    "    total = np.sum(upper_limits-lower_limits)\n",
    "    ratio = isotope_count[np.searchsorted(isotope_rt_diffs, limit, \"right\")] / total\n",
    "    ratios.append(ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "plt.plot(resolution, ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "\n",
    "plt.plot(isotope_rt_diffs, isotope_count / isotope_count[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indptr, indices = inet.get_edge_indptr_and_indices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_indices = np.repeat(np.arange(len(indptr) - 1), np.diff(indptr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "mzs = inet.get_ion_coordinates(\"MZ2\")\n",
    "diffs = np.abs(mzs[indices]-mzs[second_indices])\n",
    "\n",
    "plt.plot(*np.unique(np.round(diffs,2), return_counts=True))\n",
    "\n",
    "# plt.scatter(mzs[pairs[:,0]], diffs, marker=\".\")\n",
    "# mzds = mzs[pairs[:,0]] - mzs[pairs[:,1]]\n",
    "# sns.jointplot(mzs[pairs[:,0]], mzs[pairs[:,0]]-mzs[pairs[:,1]], kind=\"hex\", gridsize=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(network)\n",
    "# inet1 = network.Network(\n",
    "#     \"/home/sander/Documents/Proteomics/data/ion_networks/ecoli_sonar/ion_networks/28Oct2016_060_Apex3DIons.hdf\"\n",
    "# )\n",
    "inet2 = network.Network(\n",
    "    \"/home/sander/Documents/Proteomics/data/tmp.hdf\"\n",
    ")\n",
    "# inet.logger=logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = inet2.get_ion_coordinates(inet2.dimensions)\n",
    "print(inet2.dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "selection = (coords[3] > 30) & (coords[3] < 31)\n",
    "# selection=...\n",
    "\n",
    "# sns.jointplot(coords[1][selection], coords[2][selection], kind=\"hex\", gridsize=200)\n",
    "plt.scatter(coords[1][selection], coords[3][selection], marker=\".\", c=coords[0][selection], cmap=\"RdYlGn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inet2 = network.Network(\n",
    "    \"/home/sander/Documents/Sandbox/test.inet.hdf\"\n",
    ")\n",
    "# inet2=inets[0]\n",
    "\n",
    "%matplotlib notebook\n",
    "coords = inet2.get_ion_coordinates(inet2.dimensions)\n",
    "print(inet2.dimensions)\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "selection = (coords[3] > 30) & (coords[3] < 30.2)\n",
    "selection &= (coords[2] < 2000)\n",
    "selection &= (coords[1] < 900)\n",
    "# selection=...\n",
    "\n",
    "# sns.jointplot(coords[1][selection], coords[2][selection], kind=\"hex\", gridsize=200)\n",
    "ax.scatter(\n",
    "    coords[1][selection],\n",
    "    coords[3][selection],\n",
    "    coords[2][selection],\n",
    "    marker=\".\",\n",
    "    c=coords[0][selection],\n",
    "    cmap=\"RdYlGn\"\n",
    ")\n",
    "ax.set_xlabel(inet2.dimensions[1])\n",
    "ax.set_ylabel(inet2.dimensions[3])\n",
    "ax.set_zlabel(inet2.dimensions[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "coords = inet1.get_ion_coordinates(inet1.dimensions)\n",
    "print(inet1.dimensions)\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "selection = (coords[3] > 30) & (coords[3] < 31)\n",
    "selection &= (coords[2] < 2000)\n",
    "selection &= (coords[1] < 900)\n",
    "# selection=...\n",
    "\n",
    "# sns.jointplot(coords[1][selection], coords[2][selection], kind=\"hex\", gridsize=200)\n",
    "ax.scatter(\n",
    "    coords[1][selection],\n",
    "    coords[3][selection],\n",
    "    coords[2][selection],\n",
    "    marker=\".\",\n",
    "    c=coords[0][selection],\n",
    "    cmap=\"RdYlGn\"\n",
    ")\n",
    "ax.set_xlabel('MZ1')\n",
    "ax.set_ylabel('RT')\n",
    "ax.set_zlabel('MZ2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(network)\n",
    "importlib.reload(alignment)\n",
    "inets = []\n",
    "in_folder = \"/home/sander/Documents/Proteomics/data/ion_networks/ecoli_sonar/ion_networks\"\n",
    "for file_name in sorted(os.listdir(in_folder)):\n",
    "    in_file_name = os.path.join(in_folder, file_name)\n",
    "    inet = network.Network(\n",
    "        in_file_name\n",
    "    )\n",
    "    inets.append(inet)\n",
    "al = alignment.Alignment(\n",
    "    \"/home/sander/Documents/Proteomics/data/ion_networks/ecoli_sonar/alignment/alignment.hdf\"\n",
    "#     \"/home/sander/Documents/Proteomics/data/ion_networks/dda/dda_sonar_test_align.hdf\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(alignment)\n",
    "al = alignment.Alignment(\n",
    "    \"/home/sander/Documents/Proteomics/data/ion_networks/ecoli_sonar/alignment/alignment.hdf\"\n",
    "#     \"/home/sander/Documents/Proteomics/data/ion_networks/dda/dda_sonar_test_align.hdf\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "# inets = [\n",
    "#     network.Network(\"/home/sander/Documents/Proteomics/data/ion_networks/dda/tmp.hdf\"),\n",
    "#     network.Network(\"/home/sander/Documents/Proteomics/data/ion_networks/ecoli_sonar/ion_networks/28Oct2016_060_Apex3DIons.hdf\")\n",
    "# ]\n",
    "i = 0\n",
    "j = 1\n",
    "dimension = \"LOGINT\"\n",
    "\n",
    "x1, x2, x3, x4 = al.get_alignment(inets[i], inets[j])\n",
    "array1 = inets[i].get_ion_coordinates(dimension)[x1]\n",
    "array2 = inets[j].get_ion_coordinates(dimension)[x2]\n",
    "\n",
    "# plt.scatter(array1, array2, marker=\".\")\n",
    "sns.jointplot(array1, array2, kind=\"hex\", gridsize=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sandbox\n",
    "importlib.reload(sandbox)\n",
    "edges1, edges2, ali = sandbox.align_edges(inets[0], inets[1], al)\n",
    "edges1, edges2, ali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indirect = (ali.T * edges1 * ali).tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive = indirect.multiply(edges2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "available = edges2 * ali.T * ali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative = available - positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges2, indirect, available, positive, negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mzs = inets[1].get_ion_coordinates(\"MZ2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "first_indices, second_indices = edges2.nonzero()\n",
    "diffs = np.abs(mzs[first_indices]-mzs[second_indices])\n",
    "a, b = np.unique(np.round(diffs,2), return_counts=True)\n",
    "\n",
    "plt.plot(a, b / np.average(b))\n",
    "\n",
    "first_indices, second_indices = negative.nonzero()\n",
    "diffs = np.abs(mzs[first_indices]-mzs[second_indices])\n",
    "a, b = np.unique(np.round(diffs,2), return_counts=True)\n",
    "\n",
    "plt.plot(a, b / np.average(b))\n",
    "\n",
    "first_indices, second_indices = positive.nonzero()\n",
    "diffs = np.abs(mzs[first_indices]-mzs[second_indices])\n",
    "a, b = np.unique(np.round(diffs,2), return_counts=True)\n",
    "\n",
    "plt.plot(a, b / np.average(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(positive.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inets[0].node_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posi = evis[0].get_edge_mask_from_group()\n",
    "negi = evis[0].get_edge_mask_from_group(positive=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first, second = evis[0].ion_network.get_edges().nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posis = (posi == 9) & (negi == 0)\n",
    "negis = (posi == 0) & (negi == 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_posi = first[posis]\n",
    "second_posi = second[posis]\n",
    "first_negi = first[negis]\n",
    "second_negi = second[negis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posi_rtd = rts[second_posi] - rts[first_posi]\n",
    "negi_rtd = rts[second_negi] - rts[first_negi]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posi_rt_diffs, posi_count = np.unique(\n",
    "        posi_rtd,\n",
    "        return_counts=True\n",
    "    )\n",
    "posi_count = np.cumsum(posi_count)\n",
    "negi_rt_diffs, negi_count = np.unique(\n",
    "        negi_rtd,\n",
    "        return_counts=True\n",
    "    )\n",
    "negi_count = np.cumsum(negi_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "plt.plot(\n",
    "    posi_rt_diffs, posi_count / posi_count[-1]\n",
    ")\n",
    "plt.plot(\n",
    "    negi_rt_diffs, negi_count / negi_count[-1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload()\n",
    "\n",
    "interface.Interface.create_database(\n",
    "    input_path=[\n",
    "#         \"/home/sander/Documents/Proteomics/data/databases/fasta/corona.fasta\",\n",
    "        \"/home/sander/Documents/Proteomics/data/databases/fasta/crap.fasta\",\n",
    "    ],\n",
    "    output_directory=\"/home/sander/Documents/Proteomics/data/databases/hdf\",\n",
    "    parameter_file_name=\"\",\n",
    "    log_file_name=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload()\n",
    "\n",
    "db = database.Database(\"/home/sander/Documents/Proteomics/data/databases/hdf/crap_ecoli_concatenated_decoy.hdf\")\n",
    "db_mzs = db.get_fragment_coordinates(\"mz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload()\n",
    "\n",
    "interface.Interface.annotate_ion_network(\n",
    "    input_path=[\n",
    "        \"/home/sander/Documents/Proteomics/data/ecoli/28Oct2016_063.evidence.hdf\",\n",
    "        \"/home/sander/Documents/Proteomics/data/ecoli/28Oct2016_064.inet.hdf\",\n",
    "    ],\n",
    "    database_file_name=\"/home/sander/Documents/Proteomics/data/databases/hdf/corona_crap_concatenated_decoy.hdf\",\n",
    "    parameter_file_name=\"\",\n",
    "    log_file_name=\"/home/sander/Documents/Proteomics/data/ecoli/log.txt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload()\n",
    "\n",
    "# an = annotation.Annotation(\n",
    "#     evidence=evis[0],\n",
    "#     database=\"/home/sander/Documents/Proteomics/data/databases/hdf/crap_ecoli_concatenated_decoy.hdf\",\n",
    "#     parameters={\n",
    "#         \"annotation_ppm\": 20,\n",
    "#     },\n",
    "#     logger=logger\n",
    "# )\n",
    "\n",
    "an = ms_run_files.Annotation(\n",
    "    \"/home/sander/Documents/Proteomics/data/ecoli/28Oct2016_061.annotation.hdf\",\n",
    "#     new_file=True,\n",
    "#     logger=logger\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload()\n",
    "\n",
    "an.get_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.bincount(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.stack([np.arange(10), np.arange(10,20)]).T, columns = [\"one\", \"two\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"two\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.get_peptide_coordinates(\"sequence\").dtype == np.dtype('O')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload()\n",
    "\n",
    "an = annotation.Annotation(\n",
    "    evidence=evis[0]\n",
    ")\n",
    "low_peptide_indices, high_peptide_indices = an.get_candidate_peptide_indices_for_nodes(\n",
    "    db,\n",
    "    {\"annotation_ppm\": 10}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.flatnonzero(high_peptide_indices - low_peptide_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_peptides = db.get_fragment_coordinates(\"peptide_index\")\n",
    "indptr, indices = an.ion_network.get_edges(\n",
    "    indptr_and_indices=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.njit(parallel=True)\n",
    "def nb_isin(array1, array2):\n",
    "    out = np.empty(array1.shape[0], np.bool_)\n",
    "    array2_set = set(array2)\n",
    "    for i in numba.prange(array1.shape[0]):\n",
    "        out[i] = array1[i] in array2_set\n",
    "    return out\n",
    "\n",
    "\n",
    "@numba.njit\n",
    "def annotate_edges(\n",
    "    indptr,\n",
    "    indices,\n",
    "    low_peptide_indices,\n",
    "    high_peptide_indices,\n",
    "    db_peptides,\n",
    "    max_batch\n",
    "):\n",
    "    result_indptr = np.empty(indptr[-1], np.int64)\n",
    "    result_indices = np.empty(max_batch, np.int64)\n",
    "    current_index = 0\n",
    "#     max_batch = np.max(np.diff(indptr) * (high_peptide_indices - low_peptide_indices))\n",
    "    for start, end, low, high in zip(\n",
    "        indptr[:-1],\n",
    "        indptr[1:],\n",
    "        low_peptide_indices,\n",
    "        high_peptide_indices,\n",
    "    ):\n",
    "        if (low == high) or (start == end):\n",
    "            result_indptr[start:end] = current_index\n",
    "            continue\n",
    "        if ((end - start) * (high - low) + current_index) >= result_indices.shape[0]:\n",
    "            new_result_indices = np.empty(max_batch + current_index, np.int64)\n",
    "            new_result_indices[:current_index] = result_indices\n",
    "            result_indices = new_result_indices\n",
    "        peptide_candidates = db_peptides[low: high]\n",
    "        peptide_candidates_set = set(peptide_candidates)\n",
    "        neighbors = indices[start: end]\n",
    "        for i, neighbor in enumerate(neighbors):\n",
    "            neighbor_low = low_peptide_indices[neighbor]\n",
    "            neighbor_high = high_peptide_indices[neighbor]\n",
    "            if neighbor_low == neighbor_high:\n",
    "                result_indptr[start + i] = current_index\n",
    "                continue\n",
    "            neighbor_peptide_candidates = db_peptides[neighbor_low: neighbor_high]\n",
    "            for neighbor_peptide_candidate in neighbor_peptide_candidates:\n",
    "                if neighbor_peptide_candidate in peptide_candidates_set:\n",
    "                    result_indices[current_index] = neighbor_peptide_candidate\n",
    "                    current_index += 1\n",
    "            result_indptr[start + i] = current_index\n",
    "    result_indptr[1:] = result_indptr[:-1]\n",
    "    result_indptr[0] = 0\n",
    "    return result_indptr, result_indices[:current_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, aa = annotate_edges(\n",
    "    indptr[:100],\n",
    "    indices,\n",
    "    low_peptide_indices,\n",
    "    high_peptide_indices,\n",
    "    db_peptides,\n",
    "    np.max(np.diff(indptr) * (high_peptide_indices - low_peptide_indices))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "\n",
    "\n",
    "def pfunction(function):\n",
    "    def starred_function(*args, **kwargs):\n",
    "        return function(*args, **kwargs)\n",
    "    return starred_function\n",
    "\n",
    "\n",
    "def star_annotate(args, **kwargs):\n",
    "    return annotate_edges(*args, **kwargs)\n",
    "\n",
    "# with mp.Pool(8) as p:\n",
    "#     r = p.map(\n",
    "#         star_annotate,\n",
    "#         [\n",
    "#             (\n",
    "#                 indptr[i * int(np.ceil(len(indptr) / 8)): (i + 1) * int(np.ceil(len(indptr) / 8))],\n",
    "#                 indices,\n",
    "#                 low_peptide_indices,\n",
    "#                 high_peptide_indices,\n",
    "#                 db_peptides,\n",
    "#                 np.max(np.diff(indptr) * (high_peptide_indices - low_peptide_indices))\n",
    "#             ) for i in range(8)\n",
    "#         ]\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "plt.plot(np.bincount(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@sandbox.generate_in_parallel(cpu_count=4)\n",
    "@numba.njit\n",
    "def annotate_edges(\n",
    "    selection,\n",
    "    indptr,\n",
    "    indices,\n",
    "    low_peptide_indices,\n",
    "    high_peptide_indices,\n",
    "    db_peptides,\n",
    "    max_batch\n",
    "):\n",
    "    result_indptr = np.empty(indptr[-1], np.int64)\n",
    "    result_indices = np.empty(max_batch, np.int64)\n",
    "    current_index = 0\n",
    "#     max_batch = np.max(np.diff(indptr) * (high_peptide_indices - low_peptide_indices))\n",
    "    for select in selection:\n",
    "        start = indptr[select]\n",
    "        end = indptr[select + 1]\n",
    "        low = low_peptide_indices[select]\n",
    "        high = high_peptide_indices[select]\n",
    "        if (low == high) or (start == end):\n",
    "            result_indptr[start:end] = current_index\n",
    "            continue\n",
    "        if ((end - start) * (high - low) + current_index) >= result_indices.shape[0]:\n",
    "            new_result_indices = np.empty(max_batch + current_index, np.int64)\n",
    "            new_result_indices[:current_index] = result_indices\n",
    "            result_indices = new_result_indices\n",
    "        peptide_candidates = db_peptides[low: high]\n",
    "        peptide_candidates_set = set(peptide_candidates)\n",
    "        neighbors = indices[start: end]\n",
    "        for i, neighbor in enumerate(neighbors):\n",
    "            neighbor_low = low_peptide_indices[neighbor]\n",
    "            neighbor_high = high_peptide_indices[neighbor]\n",
    "            if neighbor_low == neighbor_high:\n",
    "                result_indptr[start + i] = current_index\n",
    "                continue\n",
    "            neighbor_peptide_candidates = db_peptides[neighbor_low: neighbor_high]\n",
    "            for neighbor_peptide_candidate in neighbor_peptide_candidates:\n",
    "                if neighbor_peptide_candidate in peptide_candidates_set:\n",
    "                    result_indices[current_index] = neighbor_peptide_candidate\n",
    "                    current_index += 1\n",
    "            result_indptr[start + i] = current_index\n",
    "    result_indptr[1:] = result_indptr[:-1]\n",
    "    result_indptr[0] = 0\n",
    "    return result_indptr[indptr[selection[0]]: indptr[selection[-1]]].copy(), result_indices[:current_index].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = [ \n",
    "    i for i in annotate_edges(\n",
    "#         [indptr[i*100:(i+1)*100+1] for i in range(4)],\n",
    "        np.arange(0, 100),\n",
    "        indptr,\n",
    "        indices,\n",
    "        low_peptide_indices,\n",
    "        high_peptide_indices,\n",
    "        db_peptides,\n",
    "        np.max(np.diff(indptr) * (high_peptide_indices - low_peptide_indices))\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = annotate_edges(\n",
    "#         [indptr[i*100:(i+1)*100+1] for i in range(4)],\n",
    "        np.arange(1000, 10000),\n",
    "        indptr,\n",
    "        indices,\n",
    "        low_peptide_indices,\n",
    "        high_peptide_indices,\n",
    "        db_peptides,\n",
    "        np.max(np.diff(indptr) * (high_peptide_indices - low_peptide_indices))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[indptr[i*25:(i+1)*25] for i in range(4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[indptr[:100] for i in range(4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = [ \n",
    "    i for i in parallelizedGenerator(\n",
    "        8,\n",
    "        annotate_edges,\n",
    "        [\n",
    "            indptr[i * int(np.ceil(len(indptr) / 8)): (i + 1) * int(np.ceil(len(indptr) / 8))] for i in range(8)\n",
    "        ],\n",
    "        indices,\n",
    "        low_peptide_indices,\n",
    "        high_peptide_indices,\n",
    "        db_peptides,\n",
    "        np.max(np.diff(indptr) * (high_peptide_indices - low_peptide_indices))\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "\n",
    "def parallelizedGenerator(\n",
    "    process_count,\n",
    "    function,\n",
    "    iterable,\n",
    "    *args,\n",
    "    **kwargs\n",
    "):\n",
    "    in_queue = mp.Queue()\n",
    "    out_queue = mp.Queue()\n",
    "\n",
    "    def _parallel_function():\n",
    "        while True:\n",
    "            element = in_queue.get()\n",
    "            if element is None:\n",
    "                out_queue.put(None)\n",
    "                return\n",
    "            result = function(\n",
    "                element,\n",
    "                *args,\n",
    "                **kwargs\n",
    "            )\n",
    "            out_queue.put(result)\n",
    "\n",
    "    for element in iterable:\n",
    "        in_queue.put(element)\n",
    "    processes = []\n",
    "    for process_index in range(process_count):\n",
    "        process = mp.Process(\n",
    "            target=_parallel_function,\n",
    "        )\n",
    "        in_queue.put(None)\n",
    "        process.start()\n",
    "        processes.append(process)\n",
    "    running_processes = process_count\n",
    "    while True:\n",
    "        result = out_queue.get()\n",
    "        if result is None:\n",
    "            running_processes -= 1\n",
    "            if running_processes == 0:\n",
    "                break\n",
    "        else:\n",
    "            yield result\n",
    "    in_queue.close()\n",
    "    out_queue.close()\n",
    "    in_queue.join_thread()\n",
    "    out_queue.join_thread()\n",
    "    while processes:\n",
    "        process = processes.pop()\n",
    "        process.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib notebook\n",
    "\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "inet=inets[0]\n",
    "evi=evis[0]\n",
    "\n",
    "coords = inet.get_ion_coordinates(inet.dimensions)\n",
    "repro = evi.get_aligned_nodes_from_group()\n",
    "\n",
    "fig = plt.figure(1, figsize=(13, 9))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "\n",
    "# selection = (coords[3] > 30) & (coords[3] < 30.2)\n",
    "# selection &= (coords[2] < 2000)\n",
    "# selection &= (coords[1] < 900)\n",
    "# selection=slice(0,None,10000)\n",
    "selection = repro>=25\n",
    "selection &= (coords[3] > 10) & (coords[3] < 10.1)\n",
    "\n",
    "ax.scatter(\n",
    "    coords[1][selection],\n",
    "    coords[3][selection],\n",
    "    coords[2][selection],\n",
    "    marker=\".\",\n",
    "    c=coords[0][selection],\n",
    "    cmap=\"RdYlGn\"\n",
    ")\n",
    "ax.set_xlabel(inet.dimensions[1])\n",
    "ax.set_ylabel(inet.dimensions[3])\n",
    "ax.set_zlabel(inet.dimensions[2])\n",
    "\n",
    "\n",
    "def animate(i):\n",
    "    ax.view_init(elev=30., azim=3.6*i)\n",
    "    return fig,\n",
    "\n",
    "# Animate\n",
    "ani = animation.FuncAnimation(fig, animate, \n",
    "                               frames=100, interval=100, blit=True)    \n",
    "\n",
    "HTML(ani.to_html5_video())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inet=inets[0]\n",
    "evi=evis[0]\n",
    "\n",
    "coords = inet.get_ion_coordinates(inet.dimensions)\n",
    "repro = evi.get_aligned_nodes_from_group()\n",
    "edges = inet.get_edges(data_as_index=True)\n",
    "positive_edge_evidence = evi.get_edge_mask_from_group()\n",
    "negative_edge_evidence = evi.get_edge_mask_from_group(\n",
    "    positive=False\n",
    ")\n",
    "print(inet.dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_selection = repro>=25\n",
    "node_selection &= (coords[3] > 10.0) & (coords[3] < 10.1)\n",
    "node_selection &= (coords[2] > 50) & (coords[2] < 60)\n",
    "\n",
    "\n",
    "selected_neighbors = edges[node_selection].T.tocsr()[node_selection]\n",
    "a, b = selected_neighbors.nonzero()\n",
    "positive_counts = positive_edge_evidence[\n",
    "    selected_neighbors.data\n",
    "]\n",
    "negative_counts = negative_edge_evidence[\n",
    "    selected_neighbors.data\n",
    "]\n",
    "edge_selection=...\n",
    "# edge_selection = (positive_counts >= self.min_positive_threshold)\n",
    "# edge_selection &= (positive_counts <= self.max_positive_threshold)\n",
    "# edge_selection &= (negative_counts >= self.min_negative_threshold)\n",
    "# edge_selection &= (negative_counts <= self.max_negative_threshold)\n",
    "a = a[edge_selection]\n",
    "b = b[edge_selection]\n",
    "start_edges = list(zip(coords[1][node_selection][a], coords[3][node_selection][a], coords[2][node_selection][a]))\n",
    "end_edges = list(zip(coords[1][node_selection][b], coords[3][node_selection][b], coords[2][node_selection][b]))\n",
    "colors = positive_counts[edge_selection] - negative_counts[edge_selection]\n",
    "plot_edges = np.array(list(zip(start_edges, end_edges)))\n",
    "color_order = np.argsort(colors)\n",
    "colors = colors[color_order]\n",
    "plot_edges = plot_edges[color_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "from mpl_toolkits.mplot3d import art3d\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# fig = plt.figure(1, figsize=(13, 9))\n",
    "fig = plt.figure()\n",
    "\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    \n",
    "def init_plot():\n",
    "#     edge_collection = ax.add_collection(\n",
    "#         matplotlib.collections.LineCollection([], [], [])\n",
    "#     )\n",
    "    ax.scatter(\n",
    "        coords[1][node_selection],\n",
    "        coords[3][node_selection],\n",
    "        coords[2][node_selection],\n",
    "#         marker=\".\",\n",
    "        c=coords[0][node_selection],\n",
    "        cmap=\"RdYlGn\",\n",
    "        zorder=99999,\n",
    "        s=50\n",
    "    )\n",
    "    ax.set_xlabel(inet.dimensions[1])\n",
    "    ax.set_ylabel(inet.dimensions[3])\n",
    "    ax.set_zlabel(inet.dimensions[2])\n",
    "    edge_collection = art3d.Line3DCollection(plot_edges, alpha=0.2)\n",
    "    ax.add_collection(edge_collection)\n",
    "    ax.view_init(elev=15., azim=0)\n",
    "    edge_color_mapper = matplotlib.cm.ScalarMappable(\n",
    "        norm=matplotlib.colors.Normalize(\n",
    "            # vmin=-self.evidence.evidence_count,\n",
    "            vmin=-evi.evidence_count - 1,\n",
    "            # vmin=0,\n",
    "            vmax=evi.evidence_count\n",
    "        ),\n",
    "        cmap=\"RdYlGn\"\n",
    "    )\n",
    "    edge_collection.set_color(edge_color_mapper.to_rgba(colors))\n",
    "#     ax.set_facecolor('black')\n",
    "    return fig,\n",
    "\n",
    "init_plot()\n",
    "\n",
    "def animate(i):\n",
    "    ax.view_init(elev=15., azim=3.6*i)\n",
    "    return fig,\n",
    "\n",
    "# Animate\n",
    "ani = animation.FuncAnimation(fig, animate, init_func=init_plot,\n",
    "                               frames=100, interval=100, blit=True)    \n",
    "\n",
    "# # HTML(ani.to_html5_video())\n",
    "ani.save(\"/home/sander/test.mp4\", dpi=300)\n",
    "print(\"done saving\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(60, 70):\n",
    "    in_name = f\"/home/sander/Documents/Proteomics/data/ecoli/28Oct2016_0{i}.inet.csv\"\n",
    "    out_name = f\"/home/sander/Documents/Proteomics/data/ecoli_test/28Oct2016_0{i}.inet.csv\"\n",
    "    df = pd.read_csv(in_name)\n",
    "    row_filter = (df[\"PRECURSOR_RT\"] > 50) & (df[\"PRECURSOR_RT\"] < 60)\n",
    "    # row_filter |= (df[\"PRECURSOR_MZ\"] > 500) & (df[\"PRECURSOR_MZ\"] < 600)\n",
    "    # row_filter |= (df[\"FRAGMENT_MZ\"] > 500) & (df[\"FRAGMENT_MZ\"] < 600)\n",
    "    # row_filter |= (df[\"FRAGMENT_LOGINT\"] > 10) & (df[\"FRAGMENT_LOGINT\"] < 20)\n",
    "    df[row_filter].to_csv(out_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ion_networks]",
   "language": "python",
   "name": "conda-env-ion_networks-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
