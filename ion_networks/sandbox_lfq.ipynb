{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import importlib\n",
    "from timeit import timeit\n",
    "import logging\n",
    "import sys\n",
    "import importlib\n",
    "import time\n",
    "import multiprocessing as mp\n",
    "import multiprocessing.pool\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import h5py\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import numba\n",
    "import sklearn.linear_model\n",
    "\n",
    "import ms_utils\n",
    "import browser\n",
    "import interface\n",
    "import ms_database\n",
    "import ms_run_files\n",
    "\n",
    "import sandbox\n",
    "\n",
    "import line_profiler\n",
    "profile = line_profiler.LineProfiler()\n",
    "# heat.evolve = profile(heat.evolve)\n",
    "# profile.print_stats()\n",
    "\n",
    "def reload():\n",
    "    importlib.reload(ms_run_files)\n",
    "    importlib.reload(ms_utils)\n",
    "    importlib.reload(browser)\n",
    "    importlib.reload(interface)\n",
    "    importlib.reload(sandbox)\n",
    "    importlib.reload(ms_database)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "evi = ms_run_files.HDF_Evidence_File(\"/home/sander/Documents/Proteomics/data/ecoli/28Oct2016_060.inet.csv\")\n",
    "inet = evi.ion_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_edges = evi.get_edges()\n",
    "negative_edges = evi.get_edges(positive=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indptr, indices, edge_pointers = inet.get_edges(symmetric=True, return_pointers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "evi.create_mgf(\n",
    "    {\n",
    "        \"log_file_name\": \".\",\n",
    "        \"output_directory\": \".\",\n",
    "        \"force_overwrite\": True,\n",
    "        \"minimum_peaks\": 5,\n",
    "        \"edge_threshold\": \"2 * (positive_edges - negative_edges) > evidence_run_count\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.njit\n",
    "def cluster(\n",
    "    indptr,\n",
    "    indices,\n",
    "    selected_edges,\n",
    "    edge_pointers,\n",
    "):\n",
    "    node_count = indptr.shape[0] - 1\n",
    "    clusters = np.zeros(node_count, np.int64)\n",
    "    cluster_number = 0\n",
    "    for index in range(node_count):\n",
    "        if clusters[index] != 0:\n",
    "            continue\n",
    "        current_cluster = set()\n",
    "        new_indices = set()\n",
    "        new_indices.add(index)\n",
    "        while len(new_indices) > 0:\n",
    "            new_index = new_indices.pop()\n",
    "            current_cluster.add(new_index)\n",
    "            neighbors = indices[indptr[new_index]: indptr[new_index + 1]]\n",
    "            pointers = edge_pointers[indptr[new_index]: indptr[new_index + 1]]\n",
    "            selected = selected_edges[pointers]\n",
    "            new_indices |= set(neighbors[selected]) - current_cluster\n",
    "        cluster_number += 1\n",
    "        for i in current_cluster:\n",
    "            clusters[i] = cluster_number\n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = cluster(\n",
    "    indptr,\n",
    "    indices,\n",
    "    (positive_edges - negative_edges) > 5,\n",
    "#     positive_edges==evi.run_count,\n",
    "    edge_pointers,\n",
    ")\n",
    "cluster_sizes = np.bincount(clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "( positive_edges==evi.run_count).shape, indices.shape, edge_pointers.shape[0]/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "plt.plot(np.cumsum(np.bincount(cluster_sizes)[::-1])[::-1], marker=\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_mgf(\n",
    "    inet,\n",
    "    clusters,\n",
    "    file_name,\n",
    "    minsize,\n",
    "    expand,\n",
    "    indptr,\n",
    "    indices,\n",
    "    selected_edges,\n",
    "    edge_pointers,\n",
    "):\n",
    "    cluster_indices = np.argsort(clusters)\n",
    "    cluster_indptr = np.empty(np.max(clusters + 2), np.int64)\n",
    "    cluster_indptr[0] = 0\n",
    "    cluster_indptr[1:] = np.cumsum(np.bincount(clusters))\n",
    "    mzs, ints, rts = inet.get_ion_coordinates([\"FRAGMENT_MZ\", \"FRAGMENT_LOGINT\", \"PRECURSOR_RT\"])\n",
    "    with open(file_name, \"w\") as infile:\n",
    "        for cluster_index in np.flatnonzero(np.diff(cluster_indptr) > 10):\n",
    "            infile.write(\"BEGIN IONS\\n\")\n",
    "            cluster = cluster_indices[cluster_indptr[cluster_index]: cluster_indptr[cluster_index + 1]]\n",
    "            if expand:\n",
    "                cluster = expand_cluster(\n",
    "                    cluster,\n",
    "                    indptr,\n",
    "                    indices,\n",
    "                    selected_edges,\n",
    "                    edge_pointers,\n",
    "                )\n",
    "            local_mzs = np.round(mzs[cluster], 4)\n",
    "            local_ints = np.round(2**ints[cluster], 2)\n",
    "            local_rts = rts[cluster]\n",
    "#             infile.write(\n",
    "#                 f\"TITLE=cluster_index_{cluster_index}_size_{cluster.shape[0]}\\n\"\n",
    "#             )\n",
    "            infile.write(\n",
    "                f\"TITLE=cluster_index.{cluster_index}.{cluster_index}. \"\n",
    "                f\"File=\\\"{inet.file_name}\\\" \"\n",
    "                f\"NativeID:\\\"sample=1 period=1 cycle={cluster_index-1} experiment=1\\\"\\n\"\n",
    "            )\n",
    "            infile.write(\n",
    "                f\"RTINSECONDS={np.round(np.average(local_rts) * 60, 2)}\\n\"\n",
    "            )\n",
    "            infile.write(\"PEPMASS=1000\\n\")\n",
    "            infile.write(\"CHARGE=2+\\n\")\n",
    "            mz_order = np.argsort(local_mzs)\n",
    "            for i in mz_order:\n",
    "                infile.write(f\"{local_mzs[i]} {local_ints[i]}\\n\")\n",
    "            infile.write(\"END IONS\\n\")\n",
    "\n",
    "# @numba.njit\n",
    "def expand_cluster(\n",
    "    cluster,\n",
    "    indptr,\n",
    "    indices,\n",
    "    selected_edges,\n",
    "    edge_pointers,\n",
    "):\n",
    "    new_indices = [cluster]\n",
    "    for index in cluster:\n",
    "        neighbors = indices[indptr[index]: indptr[index + 1]]\n",
    "        pointers = edge_pointers[indptr[index]: indptr[index + 1]]\n",
    "        selected = selected_edges[pointers]\n",
    "        new_indices.append(neighbors[selected])\n",
    "    return np.unique(np.concatenate(new_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_to_mgf(\n",
    "    inet=inet,\n",
    "    clusters=clusters,\n",
    "    file_name=\"/home/sander/Documents/Sandbox/test_msfragger/test.mgf\",\n",
    "    minsize=5,\n",
    "    expand=False,\n",
    "    indptr=indptr,\n",
    "    indices=indices,\n",
    "    selected_edges=(positive_edges - negative_edges) > 3,\n",
    "    edge_pointers=edge_pointers,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = ms_database.HDF_Database_File(\n",
    "    \"/home/sander/Documents/Proteomics/data/databases/crap_ecoli_concatenated_decoy.hdf\"\n",
    ")\n",
    "sequences = db.read_dataset(\"sequence\", \"proteins\")\n",
    "proteins = db.read_dataset(\"protein\", \"proteins\")\n",
    "with open(\"/home/sander/Documents/Sandbox/test_msfragger/ecoli_with_decoy.fasta\", \"w\") as infile:\n",
    "    for seq, prot in zip(sequences, proteins):\n",
    "        infile.write(f\">{prot}\\n\")\n",
    "        infile.write(f\"{seq}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmzs = inet.get_ion_coordinates(\"PRECURSOR_MZ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmzs[np.flatnonzero(clusters==988762)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_folder = \"/home/sander/projects/tenzer\"\n",
    "evis = {}\n",
    "inets = {}\n",
    "for file_name in sorted(os.listdir(in_folder)):\n",
    "    if file_name.endswith(\".evidence.hdf\"):\n",
    "        in_file_name = os.path.join(in_folder, file_name)\n",
    "        evi = ms_run_files.Evidence(in_file_name)\n",
    "        run_name = evi.run_name\n",
    "        evis[run_name] = evi\n",
    "        inet = evi.ion_network\n",
    "        inets[run_name] = inet\n",
    "\n",
    "self_run = sorted(inets)[0]\n",
    "self_inet = inets[self_run]\n",
    "self_evi = evis[self_run]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reproducibility_counts = self_evi.get_nodes()\n",
    "# alignment_indices = [\n",
    "#      np.flatnonzero(reproducibility_counts == i) for i in range(1 + self_evi.run_count)\n",
    "# ]\n",
    "# alignments = [\n",
    "#     np.empty(\n",
    "#         (alignment_indices[i].shape[0], i), np.int64\n",
    "#     ) for i in range(1 + self_evi.run_count)\n",
    "# ]\n",
    "# alignment_masks = [\n",
    "#     np.empty(\n",
    "#         (alignment_indices[i].shape[0], i), np.bool_\n",
    "#     ) for i in range(1 + self_evi.run_count)\n",
    "# ]\n",
    "\n",
    "alignment_matrix = np.empty(\n",
    "    (self_inet.node_count, self_evi.run_count), np.int64\n",
    ")\n",
    "alignment_matrix_mask = np.zeros(\n",
    "    (self_inet.node_count, self_evi.run_count), np.bool_\n",
    ")\n",
    "alignment_matrix_intensities = np.zeros(\n",
    "    (self_inet.node_count, self_evi.run_count), np.float64\n",
    ")\n",
    "\n",
    "for index, (other_run, other_evi) in enumerate(sorted(evis.items())[1:]):\n",
    "    self_ali = self_evi.get_nodes(other_evi)\n",
    "    other_ali = other_evi.get_nodes(self_evi)\n",
    "    alignment_matrix[self_ali, index] = other_ali\n",
    "    alignment_matrix_mask[self_ali, index] = True\n",
    "    alignment_matrix_intensities[self_ali, index] = 2**other_evi.ion_network.get_ion_coordinates(\n",
    "        \"FRAGMENT_LOGINT\",\n",
    "        other_ali\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_reproducibility = 1 + np.sum(alignment_matrix_mask[:, 1::2], axis=1)\n",
    "b_reproducibility = np.sum(alignment_matrix_mask[:, ::2], axis=1)\n",
    "total_reproducibility = a_reproducibility + b_reproducibility\n",
    "\n",
    "b_intensities = np.sum(alignment_matrix_intensities[:, ::2], axis=1) / b_reproducibility\n",
    "a_intensities = (\n",
    "    2**self_inet.get_ion_coordinates(\n",
    "        \"FRAGMENT_LOGINT\"\n",
    "    ) + np.sum(alignment_matrix_intensities[:, 1::2], axis=1)\n",
    ") /  a_reproducibility\n",
    "\n",
    "logfcs = np.log2(a_intensities) - np.log2(b_intensities)\n",
    "valid_logfcs = (a_reproducibility > 0) & (b_reproducibility > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "for i in range(2, 1 + 10):\n",
    "    reps = logfcs[valid_logfcs & (total_reproducibility == i)]\n",
    "    a, b = np.unique(np.round(reps, 1), return_counts=True)\n",
    "    plt.plot(a, b / np.sum(b), marker=\".\")\n",
    "\n",
    "plt.xlim((-2, 2))\n",
    "plt.xlabel(\"LOGFC\")\n",
    "plt.ylabel(\"relative frequency\")\n",
    "plt.legend(range(2, 1 + 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecoli = logfcs < -0.5\n",
    "yeast = logfcs > 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_indices, right_indices = self_inet.get_edges(\n",
    "    return_as_pairs=True,\n",
    ")\n",
    "positive_counts = self_evi.get_edges()\n",
    "negative_counts = self_evi.get_edges(positive=False)\n",
    "left_overlaps = alignment_matrix_mask[left_indices]\n",
    "right_overlaps = alignment_matrix_mask[right_indices]\n",
    "overlaps = np.sum(left_overlaps&right_overlaps, axis=1)\n",
    "logfc_deviations = np.abs(\n",
    "    logfcs[left_indices] - logfcs[right_indices]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evidence = (\n",
    "#     positive_counts - negative_counts\n",
    "# ) / (\n",
    "#     positive_counts + negative_counts\n",
    "# ) * positive_counts\n",
    "\n",
    "evidence = positive_counts - negative_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap = 4\n",
    "# int_filter = 1000\n",
    "# logints = self_inet.get_ion_coordinates(\"FRAGMENT_LOGINT\")\n",
    "selected_edges = overlaps == overlap\n",
    "# selected_edges &= (logints[left_indices] < int_filter)  & (logints[right_indices] < int_filter) \n",
    "\n",
    "selected_left_indices = left_indices[selected_edges]\n",
    "selected_right_indices = right_indices[selected_edges]\n",
    "selected_evidence = evidence[selected_edges]\n",
    "selected_nan_values = np.isnan(selected_evidence)\n",
    "selected_nan_values |= np.isinf(selected_evidence)\n",
    "selected_evidence_values = np.unique(selected_evidence[~selected_nan_values])\n",
    "\n",
    "selected_logfc_deviations = logfc_deviations[selected_edges]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "color_mapper = matplotlib.cm.ScalarMappable(\n",
    "    norm=matplotlib.colors.Normalize(\n",
    "        vmin=np.min(selected_evidence_values),\n",
    "        vmax=np.max(selected_evidence_values),\n",
    "    ),\n",
    "    cmap=\"RdYlGn\"\n",
    ")\n",
    "\n",
    "random_right_indices = selected_right_indices.copy()\n",
    "np.random.seed(100)\n",
    "np.random.shuffle(random_right_indices)\n",
    "random_logfc_deviation = np.abs(logfcs[selected_left_indices] - logfcs[random_right_indices])\n",
    "nan_values = np.isnan(random_logfc_deviation)\n",
    "nan_values |= np.isinf(random_logfc_deviation)\n",
    "random_logfc_deviation = random_logfc_deviation[~nan_values]\n",
    "plt.plot(\n",
    "    np.percentile(random_logfc_deviation, range(101)),\n",
    "    np.arange(101)/100,\n",
    "    linestyle=\"dotted\",\n",
    "    c=\"black\"\n",
    ")\n",
    "\n",
    "for evidence_value in selected_evidence_values:\n",
    "    current = selected_evidence == evidence_value\n",
    "    logfc_deviation = selected_logfc_deviations[current]\n",
    "    nan_values = np.isnan(logfc_deviation)\n",
    "    nan_values |= np.isinf(logfc_deviation)\n",
    "    logfc_deviation = logfc_deviation[~nan_values]\n",
    "    plt.plot(\n",
    "        np.percentile(logfc_deviation, range(101)),# - np.percentile(random_logfc_deviation, range(101)),\n",
    "        np.arange(101)/100,\n",
    "        c=color_mapper.to_rgba(evidence_value)\n",
    "    )\n",
    "    \n",
    "plt.axvline(\n",
    "    np.median(random_logfc_deviation),\n",
    "    linestyle=\"dotted\",\n",
    "    c=\"grey\"\n",
    ")\n",
    "# plt.legend(list(np.round(evidence_values, 1)) + [\"RANDOM\"])\n",
    "plt.colorbar(color_mapper)\n",
    "plt.xlabel(\"ABSOLUTE LOGFC DEVIATION ON EDGE\")\n",
    "plt.ylabel(\"Relative frequency\")\n",
    "plt.title(\"EDGE EVIDENCE BETWEEN FULLY REPRODUCIBLE NODES\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "color_mapper = matplotlib.cm.ScalarMappable(\n",
    "    norm=matplotlib.colors.Normalize(\n",
    "        vmin=np.min(0),\n",
    "        vmax=np.max(self_evi.run_count),\n",
    "    ),\n",
    "    cmap=\"RdYlGn\"\n",
    ")\n",
    "\n",
    "# for overlap in range(1, self_evi.run_count):\n",
    "#     selected_edges = overlaps == overlap\n",
    "if True:\n",
    "    selected_edges = overlaps >= 1\n",
    "    # selected_edges &= ecoli[left_indices] | ecoli[right_indices]\n",
    "\n",
    "    selected_left_indices = left_indices[selected_edges]\n",
    "    selected_right_indices = right_indices[selected_edges]\n",
    "    selected_evidence = evidence[selected_edges]\n",
    "    selected_nan_values = np.isnan(selected_evidence)\n",
    "    selected_nan_values |= np.isinf(selected_evidence)\n",
    "    selected_evidence_values = np.unique(selected_evidence[~selected_nan_values])\n",
    "\n",
    "\n",
    "    ecoli_hit_rates = np.empty(selected_evidence_values.shape[0], np.float64)\n",
    "    yeast_hit_rates = np.empty(selected_evidence_values.shape[0], np.float64)\n",
    "    ecoli_random_rates = np.empty(selected_evidence_values.shape[0], np.float64)\n",
    "    yeast_random_rates = np.empty(selected_evidence_values.shape[0], np.float64)\n",
    "#     total_count = np.sum(selected_edges)\n",
    "    for i, evidence_value in enumerate(selected_evidence_values):\n",
    "        current = selected_evidence == evidence_value\n",
    "        total_count = np.sum(current)\n",
    "        \n",
    "        left_ecoli = ecoli[selected_left_indices[current]]\n",
    "        right_ecoli = ecoli[selected_right_indices[current]]\n",
    "        ecoli_hit_rate = np.sum(left_ecoli & right_ecoli) / np.sum(left_ecoli | right_ecoli)\n",
    "        ecoli_hit_rates[i] = ecoli_hit_rate\n",
    "        random_right_ecoli = right_ecoli.copy()\n",
    "        np.random.shuffle(random_right_ecoli)\n",
    "        ecoli_random_rate = np.sum(left_ecoli & random_right_ecoli) / np.sum(left_ecoli | random_right_ecoli)\n",
    "        ecoli_random_rates[i] = ecoli_random_rate\n",
    "        \n",
    "        left_yeast = yeast[selected_left_indices[current]]\n",
    "        right_yeast = yeast[selected_right_indices[current]]\n",
    "        yeast_hit_rate = np.sum(left_yeast & right_yeast) / np.sum(left_yeast | right_yeast)\n",
    "        yeast_hit_rates[i] = yeast_hit_rate\n",
    "        random_right_yeast = right_yeast.copy()\n",
    "        np.random.shuffle(random_right_yeast)\n",
    "        yeast_random_rate = np.sum(left_yeast & random_right_yeast) / np.sum(left_yeast | random_right_yeast)\n",
    "        yeast_random_rates[i] = yeast_random_rate\n",
    "\n",
    "    plt.plot(\n",
    "        selected_evidence_values,\n",
    "        ecoli_hit_rates,\n",
    "        marker=\".\",\n",
    "        c=color_mapper.to_rgba(overlap)\n",
    "    )\n",
    "    plt.plot(\n",
    "        selected_evidence_values,\n",
    "        ecoli_random_rates,\n",
    "        marker=\".\",\n",
    "        c=color_mapper.to_rgba(overlap),\n",
    "        linestyle=\"dotted\",\n",
    "    )\n",
    "    plt.plot(\n",
    "        selected_evidence_values,\n",
    "        yeast_hit_rates,\n",
    "        marker=\".\",\n",
    "        c=color_mapper.to_rgba(overlap)\n",
    "    )\n",
    "    plt.plot(\n",
    "        selected_evidence_values,\n",
    "        yeast_random_rates,\n",
    "        marker=\".\",\n",
    "        c=color_mapper.to_rgba(overlap),\n",
    "        linestyle=\"dotted\",\n",
    "    )\n",
    "\n",
    "# plt.axvline(\n",
    "#     np.median(random_logfc_deviation),\n",
    "#     linestyle=\"dotted\",\n",
    "#     c=\"grey\"\n",
    "# )\n",
    "# # plt.legend(list(np.round(evidence_values, 1)) + [\"RANDOM\"])\n",
    "plt.colorbar(color_mapper)\n",
    "# plt.xlabel(\"ABSOLUTE LOGFC DEVIATION ON EDGE\")\n",
    "plt.ylabel(\"Relative frequency\")\n",
    "# plt.title(\"EDGE EVIDENCE BETWEEN FULLY REPRODUCIBLE NODES\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ion_networks]",
   "language": "python",
   "name": "conda-env-ion_networks-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
